<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://gcore.jsdelivr.net'>
  <link rel="preconnect" href="https://gcore.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>Data Mining - blacktree</title>

  
    <meta name="description" content="数据挖掘引论什么是数据挖掘 数据中的知识发现（Knowledge discover in data） 数据挖掘的基本步骤： 数据清理： 删除噪声和不一致的数据 数据集成： 将多个数据源组合在一起 数据选择： 从数据库中提取出与分析任务相关的数据 数据变换： 通过汇总或聚集操作，将数据变换和统一为适合挖掘的形式 数据挖掘： 用智能方法提取数据模式 模式评估： 用某种兴趣度度量，识别真正有趣的模式 知">
<meta property="og:type" content="article">
<meta property="og:title" content="Data Mining">
<meta property="og:url" content="http://fushunhesir.github.io/2023/04/02/Data-Mining/index.html">
<meta property="og:site_name" content="blacktree">
<meta property="og:description" content="数据挖掘引论什么是数据挖掘 数据中的知识发现（Knowledge discover in data） 数据挖掘的基本步骤： 数据清理： 删除噪声和不一致的数据 数据集成： 将多个数据源组合在一起 数据选择： 从数据库中提取出与分析任务相关的数据 数据变换： 通过汇总或聚集操作，将数据变换和统一为适合挖掘的形式 数据挖掘： 用智能方法提取数据模式 模式评估： 用某种兴趣度度量，识别真正有趣的模式 知">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%9D%87%E5%80%BC.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E8%BF%91%E4%BC%BC%E4%B8%AD%E4%BD%8D%E6%95%B0.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E6%96%B9%E5%B7%AE.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png">
<meta property="og:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png">
<meta property="article:published_time" content="2023-04-02T05:08:37.000Z">
<meta property="article:modified_time" content="2023-04-02T05:20:16.606Z">
<meta property="article:author" content="kevin.hw.he">
<meta property="article:tag" content="computer science">
<meta property="article:tag" content="economy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%9D%87%E5%80%BC.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  

  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header"><div class="logo-wrap"><a class="title" href="/"><div class="main" ff="title">blacktree</div></a></div>

<nav class="menu dis-select"></nav>
</header>


<div class="widgets">
<widget class="widget-wrapper search"><div class="widget-body"><div class="search-wrapper" id="search"><form class="search-form"><input type="text" class="search-input" id="search-input" data-filter="/blog/" placeholder="文章搜索"><svg t="1670596976048" class="icon search-icon" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2676" width="200" height="200"><path d="M938.2 832.6L723.8 618.1c-2.5-2.5-5.3-4.4-7.9-6.4 36.2-55.6 57.3-121.8 57.3-193.1C773.3 222.8 614.6 64 418.7 64S64 222.8 64 418.6c0 195.9 158.8 354.6 354.6 354.6 71.3 0 137.5-21.2 193.2-57.4 2 2.7 3.9 5.4 6.3 7.8L832.5 938c14.6 14.6 33.7 21.9 52.8 21.9 19.1 0 38.2-7.3 52.8-21.8 29.2-29.1 29.2-76.4 0.1-105.5M418.7 661.3C284.9 661.3 176 552.4 176 418.6 176 284.9 284.9 176 418.7 176c133.8 0 242.6 108.9 242.6 242.7 0 133.7-108.9 242.6-242.6 242.6" p-id="2677"></path></svg></form><div id="search-result"></div><div class="search-no-result">没有找到内容！</div></div></div></widget>


<widget class="widget-wrapper toc single" id="data-toc"><div class="widget-header cap dis-select"><span class="name">Data Mining</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%BC%95%E8%AE%BA"><span class="toc-text">引论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BB%80%E4%B9%88%E6%98%AF%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98"><span class="toc-text">什么是数据挖掘</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%96%E6%8E%98%E4%BB%80%E4%B9%88%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%95%B0%E6%8D%AE"><span class="toc-text">挖掘什么类型的数据</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%96%E6%8E%98%E4%BB%80%E4%B9%88%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%A8%A1%E5%BC%8F"><span class="toc-text">挖掘什么类型的模式</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E4%BB%80%E4%B9%88%E6%8A%80%E6%9C%AF"><span class="toc-text">使用什么技术</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%A4%E8%AF%86%E6%95%B0%E6%8D%AE"><span class="toc-text">认识数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1%E4%B8%8E%E5%B1%9E%E6%80%A7%E7%B1%BB%E5%9E%8B"><span class="toc-text">数据对象与属性类型</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%BB%9F%E8%AE%A1%E6%8F%8F%E8%BF%B0"><span class="toc-text">数据的基本统计描述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="toc-text">数据可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BA%A6%E9%87%8F%E6%95%B0%E6%8D%AE%E7%9A%84%E7%9B%B8%E4%BC%BC%E6%80%A7%E5%92%8C%E7%9B%B8%E5%BC%82%E6%80%A7"><span class="toc-text">度量数据的相似性和相异性</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86%E6%A6%82%E8%BF%B0"><span class="toc-text">数据预处理概述</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%B8%85%E7%90%86"><span class="toc-text">数据清理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E8%A7%84%E7%BA%A6"><span class="toc-text">数据规约</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%98%E6%8D%A2%E4%B8%8E%E6%95%B0%E6%8D%AE%E7%A6%BB%E6%95%A3%E5%8C%96"><span class="toc-text">数据变换与数据离散化</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%96%E6%8E%98%E9%A2%91%E7%B9%81%E6%A8%A1%E5%BC%8F%E3%80%81%E5%85%B3%E8%81%94%E5%92%8C%E7%9B%B8%E5%85%B3%E6%80%A7"><span class="toc-text">挖掘频繁模式、关联和相关性</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Aprior%E7%AE%97%E6%B3%95"><span class="toc-text">Aprior算法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A2%91%E7%B9%81%E6%A8%A1%E5%BC%8F%E5%A2%9E%E9%95%BF"><span class="toc-text">频繁模式增长</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%AA%E4%BA%9B%E6%A8%A1%E5%BC%8F%E6%98%AF%E6%9C%89%E8%B6%A3%E7%9A%84"><span class="toc-text">哪些模式是有趣的</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98"><span class="toc-text">高级模式挖掘</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-1"><span class="toc-text">基本概念</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5"><span class="toc-text">分类：基本概念</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-2"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%86%B3%E7%AD%96%E6%A0%91%E5%BD%92%E7%BA%B3"><span class="toc-text">决策树归纳</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E6%96%B9%E6%B3%95"><span class="toc-text">贝叶斯分类方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="toc-text">模型评估与选择</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%EF%BC%9A%E9%AB%98%E7%BA%A7%E6%96%B9%E6%B3%95"><span class="toc-text">分类：高级方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-3"><span class="toc-text">基本概念</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5%E5%92%8C%E6%96%B9%E6%B3%95"><span class="toc-text">聚类分析：基本概念和方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-4"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90"><span class="toc-text">聚类分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%92%E5%88%86%E6%96%B9%E6%B3%95"><span class="toc-text">划分方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B1%82%E6%AC%A1%E6%96%B9%E6%B3%95"><span class="toc-text">层次方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E5%AF%86%E5%BA%A6%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-text">基于密度的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E4%BA%8E%E7%BD%91%E6%A0%BC%E7%9A%84%E6%96%B9%E6%B3%95"><span class="toc-text">基于网格的方法</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%9A%E7%B1%BB%E8%AF%84%E4%BC%B0"><span class="toc-text">聚类评估</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90"><span class="toc-text">高级聚类分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="toc-text">离群点检测</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5-5"><span class="toc-text">基本概念</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A6%BB%E7%BE%A4%E7%82%B9%E5%92%8C%E7%A6%BB%E7%BE%A4%E7%82%B9%E5%88%86%E6%9E%90"><span class="toc-text">离群点和离群点分析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E7%BB%B4%E6%95%B0%E6%8D%AE%E4%B8%AD%E7%9A%84%E7%A6%BB%E7%BE%A4%E7%82%B9%E6%A3%80%E6%B5%8B"><span class="toc-text">高维数据中的离群点检测</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E5%8A%9F%E8%83%BD%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">数据挖掘的功能是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98%E7%9A%84%E4%B8%BB%E8%A6%81%E9%97%AE%E9%A2%98%E5%92%8C%E6%8C%91%E6%88%98%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">数据挖掘的主要问题和挑战是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E5%9B%BE%E7%9A%84%E4%BC%98%E7%BC%BA%E7%82%B9%EF%BC%8C%E9%80%82%E7%94%A8%E5%9C%BA%E6%99%AF%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">各个图的优缺点，适用场景是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E7%9A%84%E6%84%8F%E4%B9%89"><span class="toc-text">数据可视化的意义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%8F%E6%96%B9%E5%B7%AE%E7%AD%89%E4%BA%8E0%E5%8F%AF%E8%83%BD%E7%9B%B8%E5%85%B3%E4%B9%9F%E5%8F%AF%E8%83%BD%E6%97%A0%E5%85%B3"><span class="toc-text">协方差等于0可能相关也可能无关</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%AF%E4%BC%B8%E7%BC%A9%E6%80%A7%E6%98%AF%E4%BB%80%E4%B9%88"><span class="toc-text">可伸缩性是什么</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9E%82%E7%9B%B4%E6%A8%A1%E5%BC%8F%E6%8C%96%E6%8E%98%E7%9A%84%E5%A5%BD%E5%A4%84%EF%BC%8C%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E7%94%A8"><span class="toc-text">垂直模式挖掘的好处，什么时候用</span></a></li></ol></div></div></widget>




</div>


    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a></div><div id="post-meta">发布于&nbsp;<time datetime="2023-04-02T05:08:37.000Z">2023-04-02</time></div></div>

<article class='md-text content post'>
<h1 class="article-title"><span>Data Mining</span></h1>
<h1 id="数据挖掘"><a href="#数据挖掘" class="headerlink" title="数据挖掘"></a>数据挖掘</h1><h2 id="引论"><a href="#引论" class="headerlink" title="引论"></a>引论</h2><h3 id="什么是数据挖掘"><a href="#什么是数据挖掘" class="headerlink" title="什么是数据挖掘"></a>什么是数据挖掘</h3><ul>
<li><strong>数据中的知识发现</strong>（Knowledge discover in data）</li>
<li><strong>数据挖掘的基本步骤：</strong><a name='作用'></a><ol>
<li>数据清理： 删除噪声和不一致的数据</li>
<li>数据集成： 将多个数据源组合在一起</li>
<li>数据选择： 从数据库中提取出与分析任务相关的数据</li>
<li>数据变换： 通过汇总或聚集操作，将数据变换和统一为适合挖掘的形式</li>
<li>数据挖掘： 用智能方法提取数据模式</li>
<li>模式评估： 用某种兴趣度度量，识别真正有趣的模式</li>
<li>知识表示： 使用可视化和知识表示技术，向用户提供挖掘的知识</li>
</ol>
</li>
</ul>
<h3 id="挖掘什么类型的数据"><a href="#挖掘什么类型的数据" class="headerlink" title="挖掘什么类型的数据"></a>挖掘什么类型的数据</h3><ul>
<li>数据库数据</li>
<li>数据仓库</li>
<li>事务数据</li>
</ul>
<h3 id="挖掘什么类型的模式"><a href="#挖掘什么类型的模式" class="headerlink" title="挖掘什么类型的模式"></a>挖掘什么类型的模式</h3><ul>
<li><p>特征化与区分 </p>
</li>
<li><p>频繁模式，关联和相关性</p>
</li>
<li><p>预测分析：分类与回归</p>
</li>
<li><p>聚类分析</p>
</li>
<li><p>离群点分析</p>
</li>
<li><p>所有模式都是有趣的么？</p>
<p><strong>有趣：</strong>非平凡的，蕴含的，潜在有用的，先前未知的</p>
<p><strong>度量：</strong></p>
<ul>
<li><strong>客观度量</strong><ul>
<li>支持度</li>
<li>置信度</li>
</ul>
</li>
<li><strong>主观度量</strong></li>
</ul>
</li>
</ul>
<h3 id="使用什么技术"><a href="#使用什么技术" class="headerlink" title="使用什么技术"></a>使用什么技术</h3><ul>
<li>统计学</li>
<li>机器学习<ul>
<li>监督学习</li>
<li>无监督学习</li>
<li>半监督学习</li>
<li>主动学习</li>
</ul>
</li>
</ul>
<h2 id="认识数据"><a href="#认识数据" class="headerlink" title="认识数据"></a>认识数据</h2><h3 id="数据对象与属性类型"><a href="#数据对象与属性类型" class="headerlink" title="数据对象与属性类型"></a>数据对象与属性类型</h3><ul>
<li><strong>属性：</strong>是一个数据字段，表示数据对象的一个特征。</li>
<li><strong>标称属性</strong>： 一些符号或事物的名称。被视为<strong>分类的，无序的，枚举的</strong>。<ul>
<li><strong>二元属性</strong>：只有两个状态0或1，0表示不出现，1表示出现<ul>
<li><strong>对称二元属性</strong>：两种状态具有同等价值，如男性，女性</li>
<li><strong>非对称二元属性</strong>：两种状态价值不同，比如病毒检测结果阳性更具价值</li>
</ul>
</li>
</ul>
</li>
<li><strong>序数属性</strong>：值域元素之间存在有意义的序或者秩，但是排序相邻的元素之间的差值是未知的。<strong>如</strong>：大杯，中杯，小杯，我们并不知道大杯比中杯大多少，只知道这个排序。</li>
<li><strong>数值属性</strong>：定量的属性，可以用整数或者实数表示，是可以<strong>区间标度的或比率标度的</strong><ul>
<li><strong>区间标度</strong>：例如温度，可以说一个温度比另外一个温度高多少度。但是华氏度和摄氏度都不能说一个温度比另外一个温度高多少倍。<strong>它们只是有相同的单位尺度，但没有绝对的零点</strong></li>
<li><strong>比率标度</strong>：具有固定零点的数值属性。<strong>如</strong>：公司员工数量，货币量等等</li>
</ul>
</li>
<li><strong>离散属性与连续属性</strong></li>
</ul>
<h3 id="数据的基本统计描述"><a href="#数据的基本统计描述" class="headerlink" title="数据的基本统计描述"></a>数据的基本统计描述</h3><ul>
<li><p><strong>中心度量趋势</strong></p>
<ul>
<li><p><strong>均值</strong>：</p>
<ul>
<li><p><strong>普通均值</strong><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%9D%87%E5%80%BC.png" alt="image-20230218135005604"></p>
</li>
<li><p><strong>加权均值</strong><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%8A%A0%E6%9D%83%E5%B9%B3%E5%9D%87.png" alt="image-20230218135051127"></p>
</li>
<li><p><strong>截尾均值</strong>：去掉极高和极低的数据的均值</p>
</li>
</ul>
</li>
<li><p><strong>中位数</strong>：</p>
<ul>
<li><p>奇数个数据：$pos&#x3D;\frac{n+1}{2}$</p>
</li>
<li><p>偶数个数据：$pos&#x3D;[\frac{n}{2}, \frac{n}{2}+1]$</p>
</li>
<li><p><strong>近似中位数</strong>：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E8%BF%91%E4%BC%BC%E4%B8%AD%E4%BD%8D%E6%95%B0.png" alt="image-20230218140402849"></p>
</li>
</ul>
</li>
<li><p><strong>众数</strong></p>
<ul>
<li>一个数据集中可能有多个众数</li>
<li><strong>如果每个数据仅出现一次，那么该数据集没有众数</strong></li>
</ul>
</li>
<li><p><strong>中列数</strong>：一个数据集最大值和最小值的平均值</p>
</li>
<li><p><strong>数据分布</strong>：</p>
<ul>
<li><strong>对称</strong>：中位数等于众数</li>
<li><strong>非对称</strong>：<ol>
<li><strong>正倾斜</strong>：中位数大于众数</li>
<li><strong>负倾斜</strong>：中位数小于众数</li>
</ol>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>度量数据散布</strong></p>
<ul>
<li><p><strong>极差</strong>：数据集最大值和最小值的差值</p>
</li>
<li><p><strong>四分位数</strong>：用3个数据点将数据集划分为大小相等的4个子集，这三个数据点为<strong>四分位数</strong>。第二个四分位数为中位数。</p>
</li>
<li><p><strong>四分位数极差</strong>：第三个四分位数减第一个四分位数，即：$IQR&#x3D;Q_3-Q_1$，表示数据中间一半覆盖的范围。</p>
</li>
<li><p><strong>盒图</strong>：</p>
<ul>
<li>盒体上边界为： $Q_3$, 下边界为：$Q_1$</li>
<li>上胡须延长至：$max(1.5*IQR + Q_3, 极大值)$，下胡须延长至：$min(Q_1-1.5IQR, 极小值)$</li>
<li><strong>离散点</strong>：超过四分位数1.5*IQR的数据，单独画出。</li>
</ul>
</li>
<li><p><strong>方差和标准差</strong>：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E6%96%B9%E5%B7%AE.png" alt="image-20230218143341411"></p>
</li>
</ul>
</li>
<li><p><strong>基本统计描述的图形表示</strong></p>
<ul>
<li>分位数图<ul>
<li><strong>纵轴</strong>：属性的数据范围</li>
<li><strong>横轴</strong>：$f&#x3D;\frac{i-0.5}{N}$</li>
</ul>
</li>
</ul>
</li>
<li><p>分位数-分位数图</p>
<ul>
<li>直方图</li>
</ul>
</li>
<li><p>散点图</p>
</li>
</ul>
<h3 id="数据可视化"><a href="#数据可视化" class="headerlink" title="数据可视化"></a>数据可视化</h3><ul>
<li>数据可视化的意义：通过图形清晰有效的表示数据</li>
</ul>
<h3 id="度量数据的相似性和相异性"><a href="#度量数据的相似性和相异性" class="headerlink" title="度量数据的相似性和相异性"></a>度量数据的相似性和相异性</h3><ul>
<li><p><strong>数据矩阵和相异性矩阵</strong></p>
<ul>
<li><p><strong>数据矩阵</strong>：$n*p$ 矩阵，n个对象，p个属性</p>
</li>
<li><p><strong>相异性矩阵</strong>：$n*n$ 矩阵， <strong>其中元素代表相异性度量 $d(i,j)$</strong></p>
</li>
<li><p><strong>相似性度量</strong>：$sim(i,j)&#x3D;1-d(i,j)$</p>
</li>
<li><p><strong>标称属性的邻近性度量</strong>：$d(i,j) &#x3D; \frac{p-m}{p}$, 其中p为标称属性个数，m为两对象在相同的标称属性上值相同的个数。</p>
</li>
<li><p><strong>二元属性的邻近性度量</strong></p>
<ul>
<li>对称属性：$d(i,j)&#x3D;\frac{r+s}{q+r+s+t}$</li>
<li>非对称属性：$d(i,j)&#x3D;\frac{r+s}{q+r+s}$, 因为负负属性不重要，所以直接去掉</li>
</ul>
</li>
<li><p><strong>数值属性的邻近性度量：闵可夫斯基距离</strong></p>
<ul>
<li>欧几里得距离：又称<strong>L2范数</strong></li>
<li>曼哈顿距离：又称<strong>L1范数</strong></li>
<li>上确界距离：$d(i,j)&#x3D;max\lvert x_{if}-x_{jf}\rvert$, 即最大差值，也称<strong>一致范数</strong></li>
</ul>
</li>
<li><p><strong>序数属性的邻近性度量</strong>：$z_{if}&#x3D;\frac{r_{if}-1}{M_{if}-1}$, 将序数属性转化为数值属性进行计算</p>
</li>
<li><p><strong>混合类型属性的相异性</strong></p>
<p>$d(i,j)&#x3D;\frac{\sum_{f&#x3D;1}^pa_{ij}^{(f)}d_{ij}^{(f)}}{\sum_{f&#x3D;1}^pa_{ij}^{(f)}}$</p>
<ul>
<li>只要有一个对象的属性值$x_{ij}$缺失，则$a_{ij}&#x3D;0$,否则$a_{ij}&#x3D;1$</li>
<li>f为数值属性，则：$d_{ij}^{(f)}&#x3D;\frac{\lvert x_{if}-x_{jf}\rvert}{max_hx_{hf}-min_hx_{hf}}$</li>
<li>f是标称或二元，则若$x_{if}&#x3D;x_{jf}$,则$d_{ij}^{(f)}&#x3D;0$，反之为1</li>
<li>序数的就转化为数值属性处理即可</li>
</ul>
</li>
<li><p><strong>余弦相似性</strong>：<strong>针对文档等稀疏的词向量</strong></p>
</li>
</ul>
</li>
</ul>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><h3 id="数据预处理概述"><a href="#数据预处理概述" class="headerlink" title="数据预处理概述"></a>数据预处理概述</h3><ul>
<li><strong>数据质量</strong>：为什么要数据预处理<ul>
<li><strong>准确性</strong>： 数据是没有错误的</li>
<li><strong>完整性</strong>：数据属性值是完整的</li>
<li><strong>一致性</strong>：数据记录之间是没有冲突的</li>
<li><strong>时效性</strong>：时间的影响</li>
<li><strong>可信性</strong>：挖掘者是否信任该数据</li>
<li><strong>可解释性</strong>：能知道怎么解释这个数据的意义</li>
</ul>
</li>
<li><strong>数据预处理的主要任务</strong>（<a href="#%E4%BD%9C%E7%94%A8">作用</a>）<ul>
<li><strong>数据清理</strong></li>
<li><strong>数据集成</strong></li>
<li><strong>数据规约</strong></li>
<li><strong>数据变换</strong></li>
</ul>
</li>
</ul>
<h3 id="数据清理"><a href="#数据清理" class="headerlink" title="数据清理"></a>数据清理</h3><ul>
<li><p><strong>缺失值</strong></p>
<ul>
<li>忽略整个元组</li>
<li>人工填写</li>
<li>全局常量填写</li>
<li>中心度量填写</li>
<li>同一类元组的中位数或均值填充(<strong>当数据是倾斜的选择中位数</strong>)</li>
<li>最可能值填写：通过回归，贝叶斯，决策树等方法</li>
</ul>
</li>
<li><p><strong>噪声</strong></p>
<ul>
<li><strong>分箱</strong><ul>
<li>箱均值光滑</li>
<li>箱中位数光滑</li>
<li>箱边界光滑</li>
</ul>
</li>
<li><strong>回归</strong>：通过函数拟合</li>
<li><strong>离群点分析</strong>：聚类分析等方法</li>
</ul>
</li>
<li><p><strong>数据清理作为一个过程</strong></p>
<ul>
<li>偏差检测<ul>
<li>元数据：属性的数据类型和定义域，均值，中位数，倾斜还是对称</li>
<li>字段过载</li>
<li><strong>唯一性规则</strong>：值域没有重复元素</li>
<li><strong>连续性规则</strong></li>
<li><strong>空值规则</strong></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>数据集成</strong></p>
<ul>
<li><p><strong>实体识别问题</strong>：两个数据源进行属性匹配，<strong>如：cus_id与cus_num</strong></p>
</li>
<li><p><strong>冗余和相关性分析</strong></p>
<ul>
<li><p><strong>标称数据采用卡方检验</strong>：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E5%8D%A1%E6%96%B9%E6%A3%80%E9%AA%8C.png" alt="image-20230218164941969"></p>
</li>
<li><p><strong>数值属性的相关系数</strong></p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="https://cdn.jsdelivr.net/gh/fushunhesir/blog-images@main/imgs/%E7%9B%B8%E5%85%B3%E7%B3%BB%E6%95%B0.png" alt="image-20230218165230847"></p>
</li>
<li><p><strong>数值属性协方差</strong>：$Cov(A,B)&#x3D;E(AB)-E(A)E(B)$</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="数据规约"><a href="#数据规约" class="headerlink" title="数据规约"></a>数据规约</h3><ul>
<li><strong>数据规约概述</strong><ul>
<li><strong>维规约</strong>：减少属性个数，<strong>如：小波变换，主成分分析</strong></li>
<li><strong>数量规约</strong>：用较小的数据代替元数据，<strong>如：直方图，聚类，抽样</strong></li>
<li><strong>数据压缩</strong><ul>
<li>有损：近似重构原数据</li>
<li>无损：重构后不损失信息</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="数据变换与数据离散化"><a href="#数据变换与数据离散化" class="headerlink" title="数据变换与数据离散化"></a>数据变换与数据离散化</h3><ul>
<li><p><strong>数据变换策略概述</strong></p>
<ul>
<li>光滑：去掉噪声，<strong>分箱，回归，聚类</strong></li>
<li>属性构造：根据已有属性，<strong>构造新的属性</strong></li>
<li>聚集：对数据进行汇总和聚集，<strong>如根据月销售量聚集成年销售量</strong></li>
<li>规范化： <strong>将数据缩放进一个小区间内</strong></li>
<li>离散化：<strong>数值属性的原始值用区间或标签替代</strong><ul>
<li>分箱</li>
<li>直方图</li>
<li>聚类、决策树、相关分析</li>
</ul>
</li>
<li>有标称属性产生概念分层</li>
</ul>
</li>
<li><p><strong>规范化数据</strong></p>
<ul>
<li><p><strong>最大最小规范化</strong>：映射到目标区间。</p>
<p>$v^{‘}_i&#x3D;\frac{v_i-min_A}{max_A-min_A}*(new_max_A-new_min_A)+new_min_A$</p>
</li>
<li><p><strong>z分数规范化</strong>：$v^{‘}_i&#x3D;\frac{v_i-\bar{A}}{\sigma_A}$</p>
</li>
<li><p><strong>小数标定规范化</strong>：$v^{‘}_i&#x3D;\frac{v_i}{10^j}$，其中j为使v最大<strong>绝对值</strong>小于1的最小整数</p>
</li>
</ul>
</li>
</ul>
<h2 id="挖掘频繁模式、关联和相关性"><a href="#挖掘频繁模式、关联和相关性" class="headerlink" title="挖掘频繁模式、关联和相关性"></a>挖掘频繁模式、关联和相关性</h2><p>性质是什么啊。反正apple算法都是重点啊，它步骤是什么啊？如何得到关联规则啊？这个这个他的优缺点啊，然后这个这个啊改进的一些思路、一些基本思想，有什么缺陷啊等等等等等说法</p>
<p>这个是呃第六章啊最重要的算法，没有之一啊，然后其次是f算法，它跟apple算法的区别，它的思想、它的步骤，对吧？</p>
<p>这个也是有给大家布置的作业的啊优缺点啊，特别是什么？一个做这个地方我们有一个非常重要的概念，可伸缩性，对吧？所以上测试我们也有这个题目啊，可伸缩性啊。好，然后呢就是使用垂直模式挖掘的好处啊，以及使用锤子模式那种方式很简单，对吧？</p>
<p>我们一共就两页PPT啊，很简单很容易掌握，对吧？</p>
<p>什么时候用垂直模式挖掘它有啥好处？好，以及第六章最后一个部分模式评估，我们给大家介绍五个兴趣度度量啊，哪些是零不变的。什么叫零不变性啊？啊，不平衡笔是用来干嘛的。对吧？然后学会能够用他们来评估。好，这个是第六章、第七章。</p>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a><strong>基本概念</strong></h3><ul>
<li><strong>频繁模式</strong>：频繁出现在数据集中的模式(项集，子序列，子结构)</li>
<li><strong>关联规则</strong>：$A\Rightarrow B[support&#x3D;x%;confidence&#x3D;y%]$</li>
<li><strong>支持度</strong>：表示所有事务中A和B同时出现的占比，即：$P(A\cup B)$</li>
<li><strong>置信度</strong>：表示事务中A和B同时出现的次数&#x2F;事务中出现A的次数，即：$P(B|A)$</li>
<li><strong>强规则</strong>：同时满足最小支持度阈值和最小置信度阈值。</li>
<li><strong>绝对支持度</strong>：由频数作为支持度</li>
<li><strong>频繁项集</strong>：出现次数超过最小支持度计数</li>
<li><strong>挖掘关联规则的步骤</strong><ul>
<li>找出所有频繁项集</li>
<li>由频繁项集产生强关联规则</li>
</ul>
</li>
<li><strong>闭</strong>：没有真超集能够和他有相同的支持度计数</li>
<li><strong>闭频繁项集</strong>：闭+频繁</li>
<li><strong>极大频繁项集</strong>：没有超集是频繁项集</li>
<li><strong>可伸缩性</strong>：&#x3D;&#x3D;随着数据量的增加，数据挖掘算法的运行时间必须是可遇记的，短的和可以被接受的&#x3D;&#x3D;。</li>
</ul>
<h3 id="Aprior算法"><a href="#Aprior算法" class="headerlink" title="Aprior算法"></a><strong>Aprior算法</strong></h3><ul>
<li><p><strong>先验性质</strong></p>
<ul>
<li>&#x3D;&#x3D;频繁项集的所有非空子集也一定是频繁的&#x3D;&#x3D;</li>
<li>&#x3D;&#x3D;非频繁项集的的超集也一定是非频繁的&#x3D;&#x3D;</li>
</ul>
</li>
<li><p><strong>步骤</strong></p>
<ul>
<li><strong>连接步</strong></li>
<li><strong>剪枝步</strong></li>
</ul>
</li>
<li><p>&#x3D;&#x3D;<strong>缺陷</strong>：&#x3D;&#x3D;</p>
<ul>
<li>仍然可能产生大量候选集</li>
<li>可能重复扫描数据库</li>
<li>候选支持度计数工作量繁重</li>
</ul>
</li>
<li><p><strong>由频繁项集产生关联规则</strong></p>
<ul>
<li>计算置信度即可</li>
</ul>
</li>
<li><p><strong>提高Apriori算法的效率</strong></p>
<ul>
<li>基于散列，桶计数小于最小支持度计数的直接剔除</li>
<li>事务压缩</li>
<li>划分</li>
<li>抽样</li>
</ul>
</li>
</ul>
<h3 id="频繁模式增长"><a href="#频繁模式增长" class="headerlink" title="频繁模式增长"></a>频繁模式增长</h3><ul>
<li>对于挖掘长的频繁模式和短的频繁模式，它都具有有效性和可伸缩性，并且比Apriori算法快一个数量级。</li>
<li>不产生候选项</li>
<li>压缩数据库</li>
<li>不重复扫描整个数据库</li>
</ul>
<h3 id="哪些模式是有趣的"><a href="#哪些模式是有趣的" class="headerlink" title="哪些模式是有趣的"></a>哪些模式是有趣的</h3><ul>
<li><strong>提升度</strong>：$lift(A,B)&#x3D;\frac{P(A\cup B)}{P(A)P(B)}$<ul>
<li>若提升度大于1，则两者正相关</li>
<li>若提升度小于1，则两者负相关</li>
<li>若提升度等于1，则两者相互独立</li>
</ul>
</li>
<li><strong>卡方相关性分析</strong>：$X^2&#x3D;\sum\frac{(观测值-期望值)^2}{期望值}，期望值&#x3D;\frac{count(a)*count(b)}{n}$</li>
<li><strong>全置信度</strong>：$all_conf(A,B)&#x3D;\frac{sup(A\cup B)}{max{sup(A),suo(B)}}$</li>
<li><strong>最大置信度</strong>：$max_conf(A,B)&#x3D;max{P(A|B),P(B|A)}$</li>
<li><strong>Kulczynski度量</strong>：$Kulc(A,B)&#x3D;\frac{1}{2}P(A|B)+P(B|A)$</li>
<li><strong>余弦度量</strong>：$cosine(A,B)&#x3D;\frac{P(A\cup B)}{\sqrt{P(A)P(B)}}&#x3D;\sqrt{P(A|B)*P(B|A)}$</li>
</ul>
<p>&#x3D;&#x3D;所有以上度量都满足0～1，且值越大联系越紧密&#x3D;&#x3D;</p>
<ul>
<li><strong>零事务</strong>：不包含被考察的项集的事务。</li>
<li>&#x3D;&#x3D;除了提升度和卡方相关分析外，其余度量都是零不变度量，因为它们不受零事务影响&#x3D;&#x3D;</li>
</ul>
<h2 id="高级模式挖掘"><a href="#高级模式挖掘" class="headerlink" title="高级模式挖掘"></a>高级模式挖掘</h2><h3 id="基本概念-1"><a href="#基本概念-1" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>&#x3D;&#x3D;<strong>负模式</strong>：如果项集X和Y都是频繁的，但很少一起出现，则项集X与Y是负相关的，且$X\cup Y$为负模式&#x3D;&#x3D;</li>
<li>&#x3D;&#x3D;<strong>稀有模式</strong>：支持度低于用户指定的支持度阈值的模式&#x3D;&#x3D;</li>
<li></li>
</ul>
<h2 id="分类：基本概念"><a href="#分类：基本概念" class="headerlink" title="分类：基本概念"></a>分类：基本概念</h2><p>有监督学习，无监督学习概念</p>
<p>分类，数字预测概念</p>
<p>分类的步骤</p>
<p>决策树和朴素贝叶斯</p>
<p>过拟合</p>
<h3 id="基本概念-2"><a href="#基本概念-2" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li><strong>预测问题</strong><ul>
<li><strong>数值预测</strong>：回归分析是最常用的方法，<strong>例</strong>：预测一位顾客将在购物期间花多少钱。<strong>构造的模型预测一个连续值函数或有序值</strong>，这种模型称为<strong>预测器</strong></li>
<li><strong>分类</strong>：<strong>构造模型或者分类器来预测类标号</strong><ul>
<li><strong>学习阶段</strong>：构建分类模型</li>
<li><strong>分类阶段</strong>：使用模型预测给定数据的类标号</li>
<li><strong>类标号属性</strong>：离散、无序</li>
</ul>
</li>
</ul>
</li>
<li><strong>监督学习</strong>：分类器的学习在被告知每个训练元组属于哪个类的“监督”下学习</li>
<li><strong>无监督学习</strong>：每个元组的类标号是未知的，且要学习的类的个数事先也可能是未知的</li>
<li><strong>过拟合</strong>：</li>
<li><strong>准确率</strong>：分类器正确分类的测试集元组所占的百分比</li>
<li><strong>正元组</strong>：感兴趣的主要类的元组</li>
<li><strong>负元组</strong>：其他元组</li>
</ul>
<h3 id="决策树归纳"><a href="#决策树归纳" class="headerlink" title="决策树归纳"></a>决策树归纳</h3><ul>
<li><p><strong>基本算法</strong>：</p>
<ul>
<li><strong>三个参数</strong><ul>
<li><strong>数据分区</strong>：元组集合</li>
<li><strong>属性列表</strong>：元组属性的列表</li>
<li><strong>属性选择度量</strong>：基尼指数、信息增益等</li>
</ul>
</li>
<li>树从单个节点N开始</li>
<li><strong>如果</strong>D中所有元组都同一类，则节点N变成树叶，<strong>并用该类标记它</strong></li>
<li><strong>否则</strong>调用属性选择度量来指定<strong>分裂属性</strong>和<strong>分裂点</strong></li>
<li>节点N利用<strong>分裂准则</strong>标记作为节点上测试，对于分裂准则的每个输出，生成一个分支，分支中的元素由D根据分裂准则划分生成<ul>
<li><strong>属性A是离散值</strong>：划分准则就是某几个离散值</li>
<li><strong>属性A是连续值</strong>：根据分裂点划分为两个部分，生成两个分支</li>
<li><strong>属性A是离散值却必须生成二叉树</strong>：分为yes，no集合</li>
</ul>
</li>
<li>对于结果分区$D_j$递归调用函数，生成决策树。</li>
<li><strong>终止条件</strong>：<ul>
<li>分区中所有元组都属于同一类</li>
<li>没有剩余属性可供划分元组，<strong>使用多数表决</strong></li>
<li>分支没有元组，<strong>使用D中的多数类创建一个树叶</strong></li>
</ul>
</li>
<li>返回决策树</li>
</ul>
</li>
<li><p><strong>属性选择度量</strong></p>
<ul>
<li><p><strong>信息增益</strong>——越大越好</p>
<ul>
<li><p><strong>信息熵</strong>：$info(D)&#x3D;-\sum_{i&#x3D;1}^mp_ilog_2(p_i)$</p>
</li>
<li><p><strong>通过属性划分后的信息增益</strong>：$Gain(A)&#x3D;info(D)-info_A(D)$</p>
<p><strong>解释</strong>：通过对A的分裂后，未知信息减少了多少</p>
</li>
<li><p><strong>划分后的信息总量</strong>：$info_A(D)&#x3D;\sum_{i&#x3D;1}^v\frac{|D_i|}{|D|}*info(D_j)$</p>
</li>
<li><p><strong>如果处理的是连续的值那么需要选择分裂点，排序后人为划分</strong>：分裂点是两个连续值的中间值，分裂的分支数一定为<strong>2</strong></p>
</li>
<li><p><strong>缺点</strong>：偏向选择包含大量值的属性</p>
</li>
</ul>
</li>
<li><p><strong>增益率</strong>——越大越好</p>
<ul>
<li><p>$SplitInfo_A(D)&#x3D;-\sum_{j&#x3D;1}^v\frac{|D_j|}{|D|}*log_2(\frac{|D_j|}{|D|})$</p>
<p><strong>解释</strong>：以划分属性分类来计算信息熵，原来的$info(D)$是以最终的类别</p>
</li>
<li><p>$GrainRate(A)&#x3D;\frac{Grian(A)}{SplitInfo_A(D)}$</p>
</li>
</ul>
</li>
<li><p><strong>基尼指数</strong>——越小越好</p>
<ul>
<li><p>$Gini(D)&#x3D;1-\sum_{i&#x3D;1}^mp_i^2$</p>
<p><strong>代表不纯度</strong>；$p_i$代表划分子集中属于最终类的百分比；</p>
</li>
<li><p><strong>离散属性</strong>：需要将属性划分为2个子集，<strong>考虑所有划分</strong></p>
</li>
<li><p><strong>连续属性：</strong>处理方法和信息增益一致</p>
</li>
<li><p>$Gini_A(D)&#x3D;\frac{|D_1|}{|D|}Gini(D_i)+\frac{D_2}{D}Gini(D_2)$</p>
<p>$\delta Gini(A)&#x3D;Gini(D)-Gini_A(D)$</p>
</li>
<li><p><strong>要求$Gini_A(D)$越小越好，$\delta Gini(A)$越大越好</strong></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>树剪枝</strong></p>
<ul>
<li><strong>先剪枝</strong>：可以使用<strong>统计显著性、信息增益、基尼指数等度量划分的优劣，如果划分节点时低于阈值就停止划分</strong></li>
<li><strong>后剪枝</strong>：完全生长的树剪去子树。<ul>
<li><strong>CART的代价复杂度剪枝算法：</strong>用剪枝集评估代价复杂度，最小化代价复杂度为目标</li>
<li><strong>C4.5悲观剪枝</strong>：不使用剪枝集而使用训练集，基于认为训练集评估准确率或错误率过于乐观</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>可伸缩性与决策树归纳</strong></p>
<ul>
<li><strong>RainForest</strong></li>
<li><strong>BOAT</strong>：树构造的自助乐观算法 <strong>思想：</strong>取样，精度换速度</li>
</ul>
</li>
</ul>
<h3 id="贝叶斯分类方法"><a href="#贝叶斯分类方法" class="headerlink" title="贝叶斯分类方法"></a>贝叶斯分类方法</h3><ul>
<li><strong>贝叶斯定理</strong><ul>
<li><strong>后验概率</strong>：已知某些关于这件事条件，发生这事情的概率</li>
<li><strong>先验概率</strong>：一切未知的情况下，这件事发生的概率</li>
<li>$P(H|X)&#x3D;\frac{P(HX)}{p(X)}&#x3D;\frac{P(X|H)P(H)}{P(X)}$</li>
</ul>
</li>
<li><strong>朴素贝叶斯分类</strong><ul>
<li>使后验概率最大化</li>
<li><strong>类条件独立假设</strong></li>
<li><strong>如果为连续值属性</strong>：$p(x_k|C_i)&#x3D;\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}$</li>
<li><strong>步骤</strong><ul>
<li><strong>计算每个分类的先验概率</strong></li>
<li>计算不同分类下各个属性的后验概率</li>
<li><strong>计算给定条件的后验概率</strong></li>
<li><strong>计算先验概率与给定条件后验概率的乘积，选择最大的分类作为最终分类</strong></li>
</ul>
</li>
<li><strong>若存在零概率</strong>：拉普拉斯校准，在相应属性每个值各添加一个元组</li>
</ul>
</li>
</ul>
<h3 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h3><ul>
<li><strong>评估分类器性能的度量</strong><ul>
<li><strong>准确率</strong>：$accuracy&#x3D;\frac{TP+TN}{P+N}$</li>
<li><strong>错误率</strong>：$error\quad rate&#x3D;\frac{FP+FN}{P+N}$</li>
<li><strong>灵敏性,召回率</strong>：$sensitivity&#x3D;\frac{TP}{P}$</li>
<li><strong>特效性</strong>：$specificity&#x3D;\frac{TN}{N}$</li>
<li><strong>F度量</strong>：$F&#x3D;\frac{2<em>precision</em>recall}{precision+recall}$</li>
<li>$F_\beta$<strong>度量</strong>：$F_\beta&#x3D;\frac{(1+\beta^2)<em>precision</em>recall}{\beta^2*precision+recall}$</li>
</ul>
</li>
<li><strong>保持方法和随机二次抽样</strong></li>
<li><strong>交叉验证</strong></li>
</ul>
<h2 id="分类：高级方法"><a href="#分类：高级方法" class="headerlink" title="分类：高级方法"></a>分类：高级方法</h2><h3 id="基本概念-3"><a href="#基本概念-3" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>&#x3D;&#x3D;<strong>后向传播</strong>：即通过类实例标号，不断修正参数，从输出层到第一个隐藏层，最终使参数收敛&#x3D;&#x3D;</li>
<li>&#x3D;&#x3D;<strong>贝叶斯信念网络</strong>：解决朴素贝叶斯类条件独立的问题&#x3D;&#x3D;</li>
<li><strong>支持向量机</strong>：通过非线性映射，将数据映射到更高维，搜索最佳分离超平面</li>
</ul>
<h2 id="聚类分析：基本概念和方法"><a href="#聚类分析：基本概念和方法" class="headerlink" title="聚类分析：基本概念和方法"></a>聚类分析：基本概念和方法</h2><h3 id="基本概念-4"><a href="#基本概念-4" class="headerlink" title="基本概念"></a>基本概念</h3><p><strong>聚类</strong>：把数据对象划分为多个组或簇的过程，使得簇内的对象具有很高的相似性，但与其他簇中的对象很不相似</p>
<h3 id="聚类分析"><a href="#聚类分析" class="headerlink" title="聚类分析"></a>聚类分析</h3><ul>
<li><p><strong>对聚类分析的要求</strong></p>
<ul>
<li>可伸缩性</li>
<li>处理不同属性类型的能力</li>
<li>发现任意形状的簇</li>
<li>对于确定输入参数的领域知识的要求</li>
<li>处理噪声数据的能力</li>
<li>增量聚类和对输入次序不敏感</li>
<li>聚类高维数据的能力</li>
<li>基于约束的聚类</li>
<li><strong>可解释性和可用性</strong></li>
<li>划分准则</li>
<li>簇的分离性</li>
<li><strong>相似性度量</strong></li>
<li>聚类空间</li>
</ul>
</li>
<li><p><strong>基本聚类方法概述</strong></p>
<ul>
<li><p><strong>划分方法</strong></p>
<ul>
<li><p>给定一个n个对象的集合，划分方法构建数据的k个分区，其中每个分区代表一个簇，$k\leq n$</p>
<p><strong>大部分划分是基于距离的</strong>，采用<strong>迭代重定位的方法</strong></p>
<ul>
<li><strong>迭代重定位</strong>：把一个对象移动到另外一个组来改进划分。</li>
</ul>
</li>
<li><p><strong>缺点</strong>：计算量极大，相当于枚举，<strong>基于距离的方法只能发现球状簇</strong></p>
</li>
</ul>
</li>
<li><p><strong>层次方法</strong></p>
<ul>
<li><strong>凝聚</strong>：自底向上，最初将每个对象单独作为一个组，然后逐次合并相近的组或对象直到所有的组合并为一个组，或者满足某个终止条件</li>
<li><strong>分裂</strong>：自顶向下，开始将所有对象放入一个组，每次划分为一个更小的簇，或者满足某个终止条件</li>
<li><strong>缺点</strong>：一个步骤完成，就不能撤销</li>
</ul>
</li>
<li><p><strong>基于密度方法</strong></p>
<ul>
<li><strong>思想</strong>：只要邻域中的密度超过某个阈值就继续增长</li>
</ul>
</li>
<li><p><strong>基于网格</strong></p>
</li>
</ul>
</li>
</ul>
<h3 id="划分方法"><a href="#划分方法" class="headerlink" title="划分方法"></a>划分方法</h3><ul>
<li><strong>K-means：基于形心的技术</strong><ul>
<li><strong>工作流程</strong><ol>
<li>首先随机地选择k个对象，每个对象代表一个簇的初始均值或中心</li>
<li>对剩下的每个对象，根据其与各个簇中心的欧式距离，分配到最近的簇</li>
<li>利用新分配到的对象，重新计算新的中心不断迭代</li>
</ol>
</li>
<li><strong>缺点</strong><ul>
<li>不能保证k-means<strong>收敛于全局最优解</strong>，在实践中，可能会选择不同的初始簇中心运行k-means</li>
<li>需要预先定义k值，即多少个簇</li>
<li>严重受离群点影响</li>
</ul>
</li>
</ul>
</li>
<li><strong>K-中心点：一种基于代表对象的技术</strong><ul>
<li><strong>思想</strong>：不用对象的均值作为参照点，<strong>而是用一个实际对象代表簇</strong></li>
<li><strong>误差标准</strong>：$E&#x3D;\sum_{i&#x3D;1}^k\sum_{p\in C_j}dist(p,o_i)$</li>
</ul>
</li>
</ul>
<h3 id="层次方法"><a href="#层次方法" class="headerlink" title="层次方法"></a>层次方法</h3><ul>
<li><strong>凝聚的与分类的层次聚类</strong><ul>
<li>凝聚<ul>
<li><strong>每个簇都用簇中所有对象代表</strong></li>
<li>两个簇的相似度用不同簇中最近的数据点对的相似度来度量</li>
</ul>
</li>
</ul>
</li>
<li><strong>算法方法的距离度量</strong><ul>
<li><strong>最小距离</strong>：两个簇中距离最近的两个点的距离<ul>
<li><strong>如果最近的两个簇之间的距离超过阈值，聚类终止，则称其为单连接算法</strong></li>
</ul>
</li>
<li><strong>最大距离</strong>：两个簇中距离最远的两个点的距离<ul>
<li><strong>如果当最近的两个簇之间的最大距离超过阈值，聚类终止，则称其为全来接算法</strong></li>
<li><strong>如果真实的簇较为紧凑且大小近似相等</strong>，<strong>则这种方法将会产生高质量的簇，否则毫无意义</strong></li>
</ul>
</li>
<li><strong>均值距离</strong>：中心点的距离</li>
<li><strong>平均距离</strong>：<strong>计算两个簇中所有点组合的距离均值</strong></li>
</ul>
</li>
<li><strong>BIRCH：使用聚类特征树的多阶段聚类</strong><ul>
<li><strong>应用场景</strong>：大量数值数据聚类</li>
<li><strong>优点</strong>：可伸缩性，可以撤销先前步骤的工作</li>
</ul>
</li>
<li><strong>Chameleon：使用动态建模的多阶段层次聚类</strong><ul>
<li><strong>思想</strong>：动态建模确定一对簇的相似度</li>
<li><strong>优点</strong>：不用依赖于一个静态的，用户提供的模型，能够自适应</li>
</ul>
</li>
<li><strong>概率层次聚类</strong><ul>
<li><strong>思想</strong>：通过概率模型度量簇之间的距离，克服以上某些缺点</li>
</ul>
</li>
</ul>
<h3 id="基于密度的方法"><a href="#基于密度的方法" class="headerlink" title="基于密度的方法"></a>基于密度的方法</h3><ul>
<li><strong>DBSCAN：一种基于高密度连通区域的基于密度的聚类</strong><ul>
<li><strong>核心对象</strong>：<em>邻域内的对象数量大于等于阈值</em></li>
<li><strong>邻域密度</strong>：邻域内的对象数度量</li>
<li><strong>直接密度可达</strong>：该点在<strong>核心对象</strong>点邻域中</li>
<li><strong>密度可达</strong>：<em>直接密度可达传递</em>，<strong>出发点和中间点必须是核心对象</strong></li>
<li><strong>密度相连</strong>：<em>两个中心能够从同一个点密度可达</em></li>
</ul>
</li>
</ul>
<h3 id="基于网格的方法"><a href="#基于网格的方法" class="headerlink" title="基于网格的方法"></a>基于网格的方法</h3><ul>
<li><strong>思想</strong>：将对象空间量化为有限数目的单元，这些单元形成了网格结构，所有的聚类操作都在该结构上进行</li>
<li><strong>优点</strong>：处理速度快，处理速度进依赖于量化空间中每一维上的单元数</li>
</ul>
<h3 id="聚类评估"><a href="#聚类评估" class="headerlink" title="聚类评估"></a>聚类评估</h3><p>* </p>
<h2 id="高级聚类分析"><a href="#高级聚类分析" class="headerlink" title="高级聚类分析"></a>高级聚类分析</h2><h2 id="离群点检测"><a href="#离群点检测" class="headerlink" title="离群点检测"></a>离群点检测</h2><p>什么是离终点啊。离群点和其他的一些相似概念有什么区别啊？离群点点的定义啊，经典的三种离群点的分类啊，离群点检测是个什么概念啊？这样一些啊。</p>
<p>然后呢就是四种离群点检测的方法，他们的原理，他们的假设，特别是他们的假设是什么？原理是什么？特点是什么啊，优缺点是什么啊，然后有监督、无监督从另外一个角度来划分，有监督、无监督、半监督这种离群点检测啊，他们的概念、特点啊是什么啊？</p>
<p>啊，优势。优缺点，优势是什么？适用于什么样的场景。对吧？啊，然后最后就是对于高危的触点它的挑战是什么？它的困难是什么？啊，基本思路是什么啊？挖掘情景的清点和集体的景点啊，他的思路是什么啊。这个这个对困难在什么地方？对吧？</p>
<h3 id="基本概念-5"><a href="#基本概念-5" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li><strong>离群点</strong>：显著不同于其他数据对象的数据对象</li>
</ul>
<h3 id="离群点和离群点分析"><a href="#离群点和离群点分析" class="headerlink" title="离群点和离群点分析"></a>离群点和离群点分析</h3><ul>
<li><strong>离群点的类型</strong><ul>
<li><strong>全局离群点</strong><ul>
<li>显著的偏离数据中的其他对象</li>
</ul>
</li>
<li><strong>情景离群点</strong><ul>
<li>关于对象的特定情景，显著地偏离其他对象。 比如夏天-1度</li>
</ul>
</li>
<li><strong>集体离群点</strong><ul>
<li>单个点或许不是离群点，<strong>但是这群点的集合是异常点</strong></li>
</ul>
</li>
</ul>
</li>
<li><strong>离群点检测方法</strong><ul>
<li><strong>监督半监督无监督方法</strong><ul>
<li>监督方法：专家标记基础数据的样本<ul>
<li>缺点：<ol>
<li>离群点总体数量少，专家标记样本可能不足以代表离群点分</li>
</ol>
</li>
</ul>
</li>
<li><strong>无监督方法</strong><ul>
<li><strong>假设</strong>：正常对象在某种程度上是聚类的</li>
<li><strong>缺点</strong>：不属于簇的可能是噪声而不是离群点，开销大</li>
</ul>
</li>
<li><strong>半监督方法</strong></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="高维数据中的离群点检测"><a href="#高维数据中的离群点检测" class="headerlink" title="高维数据中的离群点检测"></a>高维数据中的离群点检测</h3><ul>
<li><strong>挑战</strong><ul>
<li><strong>离群点的解释</strong></li>
<li><strong>数据的稀疏性</strong></li>
<li><strong>数据子空间</strong></li>
<li><strong>关于维度的可伸缩性</strong></li>
<li></li>
</ul>
</li>
</ul>
<h1 id="Question"><a href="#Question" class="headerlink" title="Question"></a>Question</h1><h2 id="数据挖掘的功能是什么"><a href="#数据挖掘的功能是什么" class="headerlink" title="数据挖掘的功能是什么"></a>数据挖掘的功能是什么</h2><h2 id="数据挖掘的主要问题和挑战是什么"><a href="#数据挖掘的主要问题和挑战是什么" class="headerlink" title="数据挖掘的主要问题和挑战是什么"></a>数据挖掘的主要问题和挑战是什么</h2><h2 id="各个图的优缺点，适用场景是什么"><a href="#各个图的优缺点，适用场景是什么" class="headerlink" title="各个图的优缺点，适用场景是什么"></a>各个图的优缺点，适用场景是什么</h2><h2 id="数据可视化的意义"><a href="#数据可视化的意义" class="headerlink" title="数据可视化的意义"></a>数据可视化的意义</h2><h2 id="协方差等于0可能相关也可能无关"><a href="#协方差等于0可能相关也可能无关" class="headerlink" title="协方差等于0可能相关也可能无关"></a>协方差等于0可能相关也可能无关</h2><h2 id="可伸缩性是什么"><a href="#可伸缩性是什么" class="headerlink" title="可伸缩性是什么"></a>可伸缩性是什么</h2><h2 id="垂直模式挖掘的好处，什么时候用"><a href="#垂直模式挖掘的好处，什么时候用" class="headerlink" title="垂直模式挖掘的好处，什么时候用"></a>垂直模式挖掘的好处，什么时候用</h2>

<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"><div class="note">较新文章</div><a href="/2023/04/02/Data-Structure/">Data Structure</a></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/03/16/MIT-6-S081/">MIT 6.S081</a></div></section></div>








      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/">@anonymity</a> 使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a> 主题创建。<br>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  const stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.18.5';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.18.5';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://gcore.jsdelivr.net/npm/jquery@3.6.2/dist/jquery.min.js'
  };

  if ('local_search') {
    stellar.search = {};
    stellar.search.service = 'local_search';
    if (stellar.search.service == 'local_search') {
      let service_obj = Object.assign({}, {"field":"all","path":"/search.json","content":true,"sort":"-date"});
      stellar.search[stellar.search.service] = service_obj;
    }
  }

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js","weibo":"/js/plugins/weibo.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/vanilla-lazyload@17.8.3/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.css","js":"https://unpkg.com/swiper@8.4.5/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://gcore.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://gcore.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://gcore.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://gcore.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti@0.9.2/umd/heti.min.css","js":"https://unpkg.com/heti@0.9.2/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->



<!-- inject -->


  </div>
</body>
</html>
