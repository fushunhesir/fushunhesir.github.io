[{"title":"Hello World","path":"/2023/04/02/hello-world/","content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new &quot;My New Post&quot; More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment"},{"title":"Data Structure","path":"/2023/04/02/Data-Structure/","content":"数据结构 绪论 数据结构基本概念 基本概念和术语 数据：不是简单指数字，而是代指一切能够输入计算机内部的符号，并且该符号承载了信息以及事物的属性 数据元素：是一个整体结构，内部包含数据项，数据项是组成数据元素的最小单位。比如：学生（学号、姓名、班级） 数据对象：具有相同性质的数据元素的集合，如：数据库中元组和关系，元组是数据元素，关系是数据对象 数据类型 原子类型：不可再分的类型，如：基本数据类型int， double 结构类型：可再分的类型，如：struct 抽象数据类型：既有数据集合，又有对该集合操作的类型，如：类 数据结构 本质：==数据元素的集合==。集合内的数据元素之间存在特定的关系，如：树，图，链表等。简单理解，就是以什么形式(结构)组织数据元素，以适用于特定的应用场景 三要素：逻辑结构，物理结构(存储结构)，对数据元素的操作(数据运算) 数据结构三要素 逻辑结构：独立于物理存储和计算机的结构，是人为设计的抽象结构。主要分为线性结构，非线性结构 存储结构 顺序存储：物理上连续的存储，优点：占用空间小，可以随机存取 缺点：产生外部碎片 链式存储：物理上不一定连续的存储，优点：充分利用存储，不会产生碎片，缺点：指针占用额外空间，且只能顺序存取 索引存储：创建索引表辅助。优点：检索速度快，缺点：索引表占用额外空间，插入和删除需要修改索引表，增加额外开销 哈希存储：通过散列函数计算存储地址。优点：所有操作都很快。缺点：可能出现冲突，解决冲突会增加时间开销 算法和算法评价 算法 定义：解决特定问题的有限指令序列 5大性质； 确定性：每一步描述是没有确定的，没有疑义的 有穷性：步骤是有限的 可行性：每一步都是可以实现的 输入 输出 目标 正确性 可读性 健壮性：能够对非法输入合理处理 算法效率度量 时间复杂度 * 空间复杂度"},{"title":"Data Mining","path":"/2023/04/02/Data-Mining/","content":"数据挖掘 引论 什么是数据挖掘 数据中的知识发现（Knowledge discover in data） 数据挖掘的基本步骤： 数据清理： 删除噪声和不一致的数据 数据集成： 将多个数据源组合在一起 数据选择： 从数据库中提取出与分析任务相关的数据 数据变换： 通过汇总或聚集操作，将数据变换和统一为适合挖掘的形式 数据挖掘： 用智能方法提取数据模式 模式评估： 用某种兴趣度度量，识别真正有趣的模式 知识表示： 使用可视化和知识表示技术，向用户提供挖掘的知识 挖掘什么类型的数据 数据库数据 数据仓库 事务数据 挖掘什么类型的模式 特征化与区分 频繁模式，关联和相关性 预测分析：分类与回归 聚类分析 离群点分析 所有模式都是有趣的么？ **有趣：**非平凡的，蕴含的，潜在有用的，先前未知的 度量： 客观度量 支持度 置信度 主观度量 使用什么技术 统计学 机器学习 监督学习 无监督学习 半监督学习 主动学习 认识数据 数据对象与属性类型 **属性：**是一个数据字段，表示数据对象的一个特征。 标称属性： 一些符号或事物的名称。被视为分类的，无序的，枚举的。 二元属性：只有两个状态0或1，0表示不出现，1表示出现 对称二元属性：两种状态具有同等价值，如男性，女性 非对称二元属性：两种状态价值不同，比如病毒检测结果阳性更具价值 序数属性：值域元素之间存在有意义的序或者秩，但是排序相邻的元素之间的差值是未知的。如：大杯，中杯，小杯，我们并不知道大杯比中杯大多少，只知道这个排序。 数值属性：定量的属性，可以用整数或者实数表示，是可以区间标度的或比率标度的 区间标度：例如温度，可以说一个温度比另外一个温度高多少度。但是华氏度和摄氏度都不能说一个温度比另外一个温度高多少倍。它们只是有相同的单位尺度，但没有绝对的零点 比率标度：具有固定零点的数值属性。如：公司员工数量，货币量等等 离散属性与连续属性 数据的基本统计描述 中心度量趋势 均值： 普通均值 加权均值 截尾均值：去掉极高和极低的数据的均值 中位数： 奇数个数据： 偶数个数据： 近似中位数： 众数 一个数据集中可能有多个众数 如果每个数据仅出现一次，那么该数据集没有众数 中列数：一个数据集最大值和最小值的平均值 数据分布： 对称：中位数等于众数 非对称： 正倾斜：中位数大于众数 负倾斜：中位数小于众数 度量数据散布 极差：数据集最大值和最小值的差值 四分位数：用3个数据点将数据集划分为大小相等的4个子集，这三个数据点为四分位数。第二个四分位数为中位数。 四分位数极差：第三个四分位数减第一个四分位数，即：，表示数据中间一半覆盖的范围。 盒图： 盒体上边界为： , 下边界为： 上胡须延长至：极大值，下胡须延长至：极小值 离散点：超过四分位数1.5*IQR的数据，单独画出。 方差和标准差： 基本统计描述的图形表示 分位数图 纵轴：属性的数据范围 横轴： 分位数-分位数图 直方图 散点图 数据可视化 数据可视化的意义：通过图形清晰有效的表示数据 度量数据的相似性和相异性 数据矩阵和相异性矩阵 数据矩阵： 矩阵，n个对象，p个属性 相异性矩阵： 矩阵， 其中元素代表相异性度量 相似性度量： 标称属性的邻近性度量：, 其中p为标称属性个数，m为两对象在相同的标称属性上值相同的个数。 二元属性的邻近性度量 对称属性： 非对称属性：, 因为负负属性不重要，所以直接去掉 数值属性的邻近性度量：闵可夫斯基距离 欧几里得距离：又称L2范数 曼哈顿距离：又称L1范数 上确界距离：, 即最大差值，也称一致范数 序数属性的邻近性度量：, 将序数属性转化为数值属性进行计算 混合类型属性的相异性 只要有一个对象的属性值缺失，则,否则 f为数值属性，则： f是标称或二元，则若,则，反之为1 序数的就转化为数值属性处理即可 余弦相似性：针对文档等稀疏的词向量 数据预处理 数据预处理概述 数据质量：为什么要数据预处理 准确性： 数据是没有错误的 完整性：数据属性值是完整的 一致性：数据记录之间是没有冲突的 时效性：时间的影响 可信性：挖掘者是否信任该数据 可解释性：能知道怎么解释这个数据的意义 数据预处理的主要任务（作用） 数据清理 数据集成 数据规约 数据变换 数据清理 缺失值 忽略整个元组 人工填写 全局常量填写 中心度量填写 同一类元组的中位数或均值填充(当数据是倾斜的选择中位数) 最可能值填写：通过回归，贝叶斯，决策树等方法 噪声 分箱 箱均值光滑 箱中位数光滑 箱边界光滑 回归：通过函数拟合 离群点分析：聚类分析等方法 数据清理作为一个过程 偏差检测 元数据：属性的数据类型和定义域，均值，中位数，倾斜还是对称 字段过载 唯一性规则：值域没有重复元素 连续性规则 空值规则 数据集成 实体识别问题：两个数据源进行属性匹配，如：cus_id与cus_num 冗余和相关性分析 标称数据采用卡方检验： 数值属性的相关系数 数值属性协方差： 数据规约 数据规约概述 维规约：减少属性个数，如：小波变换，主成分分析 数量规约：用较小的数据代替元数据，如：直方图，聚类，抽样 数据压缩 有损：近似重构原数据 无损：重构后不损失信息 数据变换与数据离散化 数据变换策略概述 光滑：去掉噪声，分箱，回归，聚类 属性构造：根据已有属性，构造新的属性 聚集：对数据进行汇总和聚集，如根据月销售量聚集成年销售量 规范化： 将数据缩放进一个小区间内 离散化：数值属性的原始值用区间或标签替代 分箱 直方图 聚类、决策树、相关分析 有标称属性产生概念分层 规范化数据 最大最小规范化：映射到目标区间。 z分数规范化： 小数标定规范化：，其中j为使v最大绝对值小于1的最小整数 挖掘频繁模式、关联和相关性 性质是什么啊。反正apple算法都是重点啊，它步骤是什么啊？如何得到关联规则啊？这个这个他的优缺点啊，然后这个这个啊改进的一些思路、一些基本思想，有什么缺陷啊等等等等等说法 这个是呃第六章啊最重要的算法，没有之一啊，然后其次是f算法，它跟apple算法的区别，它的思想、它的步骤，对吧？ 这个也是有给大家布置的作业的啊优缺点啊，特别是什么？一个做这个地方我们有一个非常重要的概念，可伸缩性，对吧？所以上测试我们也有这个题目啊，可伸缩性啊。好，然后呢就是使用垂直模式挖掘的好处啊，以及使用锤子模式那种方式很简单，对吧？ 我们一共就两页PPT啊，很简单很容易掌握，对吧？ 什么时候用垂直模式挖掘它有啥好处？好，以及第六章最后一个部分模式评估，我们给大家介绍五个兴趣度度量啊，哪些是零不变的。什么叫零不变性啊？啊，不平衡笔是用来干嘛的。对吧？然后学会能够用他们来评估。好，这个是第六章、第七章。 基本概念 频繁模式：频繁出现在数据集中的模式(项集，子序列，子结构) 关联规则： 支持度：表示所有事务中A和B同时出现的占比，即： 置信度：表示事务中A和B同时出现的次数/事务中出现A的次数，即： 强规则：同时满足最小支持度阈值和最小置信度阈值。 绝对支持度：由频数作为支持度 频繁项集：出现次数超过最小支持度计数 挖掘关联规则的步骤 找出所有频繁项集 由频繁项集产生强关联规则 闭：没有真超集能够和他有相同的支持度计数 闭频繁项集：闭+频繁 极大频繁项集：没有超集是频繁项集 可伸缩性：==随着数据量的增加，数据挖掘算法的运行时间必须是可遇记的，短的和可以被接受的==。 Aprior算法 先验性质 ==频繁项集的所有非空子集也一定是频繁的== ==非频繁项集的的超集也一定是非频繁的== 步骤 连接步 剪枝步 ==缺陷：== 仍然可能产生大量候选集 可能重复扫描数据库 候选支持度计数工作量繁重 由频繁项集产生关联规则 计算置信度即可 提高Apriori算法的效率 基于散列，桶计数小于最小支持度计数的直接剔除 事务压缩 划分 抽样 频繁模式增长 对于挖掘长的频繁模式和短的频繁模式，它都具有有效性和可伸缩性，并且比Apriori算法快一个数量级。 不产生候选项 压缩数据库 不重复扫描整个数据库 哪些模式是有趣的 提升度： 若提升度大于1，则两者正相关 若提升度小于1，则两者负相关 若提升度等于1，则两者相互独立 卡方相关性分析：观测值期望值期望值，期望值 全置信度： 最大置信度： Kulczynski度量： 余弦度量： ==所有以上度量都满足0～1，且值越大联系越紧密== 零事务：不包含被考察的项集的事务。 ==除了提升度和卡方相关分析外，其余度量都是零不变度量，因为它们不受零事务影响== 高级模式挖掘 基本概念 ==负模式：如果项集X和Y都是频繁的，但很少一起出现，则项集X与Y是负相关的，且为负模式== ==稀有模式：支持度低于用户指定的支持度阈值的模式== 分类：基本概念 有监督学习，无监督学习概念 分类，数字预测概念 分类的步骤 决策树和朴素贝叶斯 过拟合 基本概念 预测问题 数值预测：回归分析是最常用的方法，例：预测一位顾客将在购物期间花多少钱。构造的模型预测一个连续值函数或有序值，这种模型称为预测器 分类：构造模型或者分类器来预测类标号 学习阶段：构建分类模型 分类阶段：使用模型预测给定数据的类标号 类标号属性：离散、无序 监督学习：分类器的学习在被告知每个训练元组属于哪个类的“监督”下学习 无监督学习：每个元组的类标号是未知的，且要学习的类的个数事先也可能是未知的 过拟合： 准确率：分类器正确分类的测试集元组所占的百分比 正元组：感兴趣的主要类的元组 负元组：其他元组 决策树归纳 基本算法： 三个参数 数据分区：元组集合 属性列表：元组属性的列表 属性选择度量：基尼指数、信息增益等 树从单个节点N开始 如果D中所有元组都同一类，则节点N变成树叶，并用该类标记它 否则调用属性选择度量来指定分裂属性和分裂点 节点N利用分裂准则标记作为节点上测试，对于分裂准则的每个输出，生成一个分支，分支中的元素由D根据分裂准则划分生成 属性A是离散值：划分准则就是某几个离散值 属性A是连续值：根据分裂点划分为两个部分，生成两个分支 属性A是离散值却必须生成二叉树：分为yes，no集合 对于结果分区递归调用函数，生成决策树。 终止条件： 分区中所有元组都属于同一类 没有剩余属性可供划分元组，使用多数表决 分支没有元组，使用D中的多数类创建一个树叶 返回决策树 属性选择度量 信息增益——越大越好 信息熵： 通过属性划分后的信息增益： 解释：通过对A的分裂后，未知信息减少了多少 划分后的信息总量： 如果处理的是连续的值那么需要选择分裂点，排序后人为划分：分裂点是两个连续值的中间值，分裂的分支数一定为2 缺点：偏向选择包含大量值的属性 增益率——越大越好 解释：以划分属性分类来计算信息熵，原来的是以最终的类别 基尼指数——越小越好 代表不纯度；代表划分子集中属于最终类的百分比； 离散属性：需要将属性划分为2个子集，考虑所有划分 **连续属性：**处理方法和信息增益一致 要求越小越好，越大越好 树剪枝 先剪枝：可以使用统计显著性、信息增益、基尼指数等度量划分的优劣，如果划分节点时低于阈值就停止划分 后剪枝：完全生长的树剪去子树。 **CART的代价复杂度剪枝算法：**用剪枝集评估代价复杂度，最小化代价复杂度为目标 C4.5悲观剪枝：不使用剪枝集而使用训练集，基于认为训练集评估准确率或错误率过于乐观 可伸缩性与决策树归纳 RainForest BOAT：树构造的自助乐观算法 **思想：**取样，精度换速度 贝叶斯分类方法 贝叶斯定理 后验概率：已知某些关于这件事条件，发生这事情的概率 先验概率：一切未知的情况下，这件事发生的概率 朴素贝叶斯分类 使后验概率最大化 类条件独立假设 如果为连续值属性： 步骤 计算每个分类的先验概率 计算不同分类下各个属性的后验概率 计算给定条件的后验概率 计算先验概率与给定条件后验概率的乘积，选择最大的分类作为最终分类 若存在零概率：拉普拉斯校准，在相应属性每个值各添加一个元组 模型评估与选择 评估分类器性能的度量 准确率： 错误率： 灵敏性,召回率： 特效性： F度量： 度量： 保持方法和随机二次抽样 交叉验证 分类：高级方法 基本概念 ==后向传播：即通过类实例标号，不断修正参数，从输出层到第一个隐藏层，最终使参数收敛== ==贝叶斯信念网络：解决朴素贝叶斯类条件独立的问题== 支持向量机：通过非线性映射，将数据映射到更高维，搜索最佳分离超平面 聚类分析：基本概念和方法 基本概念 聚类：把数据对象划分为多个组或簇的过程，使得簇内的对象具有很高的相似性，但与其他簇中的对象很不相似 聚类分析 对聚类分析的要求 可伸缩性 处理不同属性类型的能力 发现任意形状的簇 对于确定输入参数的领域知识的要求 处理噪声数据的能力 增量聚类和对输入次序不敏感 聚类高维数据的能力 基于约束的聚类 可解释性和可用性 划分准则 簇的分离性 相似性度量 聚类空间 基本聚类方法概述 划分方法 给定一个n个对象的集合，划分方法构建数据的k个分区，其中每个分区代表一个簇， 大部分划分是基于距离的，采用迭代重定位的方法 迭代重定位：把一个对象移动到另外一个组来改进划分。 缺点：计算量极大，相当于枚举，基于距离的方法只能发现球状簇 层次方法 凝聚：自底向上，最初将每个对象单独作为一个组，然后逐次合并相近的组或对象直到所有的组合并为一个组，或者满足某个终止条件 分裂：自顶向下，开始将所有对象放入一个组，每次划分为一个更小的簇，或者满足某个终止条件 缺点：一个步骤完成，就不能撤销 基于密度方法 思想：只要邻域中的密度超过某个阈值就继续增长 基于网格 划分方法 K-means：基于形心的技术 工作流程 首先随机地选择k个对象，每个对象代表一个簇的初始均值或中心 对剩下的每个对象，根据其与各个簇中心的欧式距离，分配到最近的簇 利用新分配到的对象，重新计算新的中心不断迭代 缺点 不能保证k-means收敛于全局最优解，在实践中，可能会选择不同的初始簇中心运行k-means 需要预先定义k值，即多少个簇 严重受离群点影响 K-中心点：一种基于代表对象的技术 思想：不用对象的均值作为参照点，而是用一个实际对象代表簇 误差标准： 层次方法 凝聚的与分类的层次聚类 凝聚 每个簇都用簇中所有对象代表 两个簇的相似度用不同簇中最近的数据点对的相似度来度量 算法方法的距离度量 最小距离：两个簇中距离最近的两个点的距离 如果最近的两个簇之间的距离超过阈值，聚类终止，则称其为单连接算法 最大距离：两个簇中距离最远的两个点的距离 如果当最近的两个簇之间的最大距离超过阈值，聚类终止，则称其为全来接算法 如果真实的簇较为紧凑且大小近似相等，则这种方法将会产生高质量的簇，否则毫无意义 均值距离：中心点的距离 平均距离：计算两个簇中所有点组合的距离均值 BIRCH：使用聚类特征树的多阶段聚类 应用场景：大量数值数据聚类 优点：可伸缩性，可以撤销先前步骤的工作 Chameleon：使用动态建模的多阶段层次聚类 思想：动态建模确定一对簇的相似度 优点：不用依赖于一个静态的，用户提供的模型，能够自适应 概率层次聚类 思想：通过概率模型度量簇之间的距离，克服以上某些缺点 基于密度的方法 DBSCAN：一种基于高密度连通区域的基于密度的聚类 核心对象：邻域内的对象数量大于等于阈值 邻域密度：邻域内的对象数度量 直接密度可达：该点在核心对象点邻域中 密度可达：直接密度可达传递，出发点和中间点必须是核心对象 密度相连：两个中心能够从同一个点密度可达 基于网格的方法 思想：将对象空间量化为有限数目的单元，这些单元形成了网格结构，所有的聚类操作都在该结构上进行 优点：处理速度快，处理速度进依赖于量化空间中每一维上的单元数 聚类评估 高级聚类分析 离群点检测 什么是离终点啊。离群点和其他的一些相似概念有什么区别啊？离群点点的定义啊，经典的三种离群点的分类啊，离群点检测是个什么概念啊？这样一些啊。 然后呢就是四种离群点检测的方法，他们的原理，他们的假设，特别是他们的假设是什么？原理是什么？特点是什么啊，优缺点是什么啊，然后有监督、无监督从另外一个角度来划分，有监督、无监督、半监督这种离群点检测啊，他们的概念、特点啊是什么啊？ 啊，优势。优缺点，优势是什么？适用于什么样的场景。对吧？啊，然后最后就是对于高危的触点它的挑战是什么？它的困难是什么？啊，基本思路是什么啊？挖掘情景的清点和集体的景点啊，他的思路是什么啊。这个这个对困难在什么地方？对吧？ 基本概念 离群点：显著不同于其他数据对象的数据对象 离群点和离群点分析 离群点的类型 全局离群点 显著的偏离数据中的其他对象 情景离群点 关于对象的特定情景，显著地偏离其他对象。 比如夏天-1度 集体离群点 单个点或许不是离群点，但是这群点的集合是异常点 离群点检测方法 监督半监督无监督方法 监督方法：专家标记基础数据的样本 缺点： 离群点总体数量少，专家标记样本可能不足以代表离群点分 无监督方法 假设：正常对象在某种程度上是聚类的 缺点：不属于簇的可能是噪声而不是离群点，开销大 半监督方法 高维数据中的离群点检测 挑战 离群点的解释 数据的稀疏性 数据子空间 关于维度的可伸缩性 Question 数据挖掘的功能是什么 数据挖掘的主要问题和挑战是什么 各个图的优缺点，适用场景是什么 数据可视化的意义 协方差等于0可能相关也可能无关 可伸缩性是什么 垂直模式挖掘的好处，什么时候用"},{"title":"MIT 6.S081","path":"/2023/03/16/MIT-6-S081/","content":"MIT 6.S081 Lab Lab 3 检测被访问过的页面 背景：一些垃圾回收机制如果能够获取页面是否被访问的信息，将能够提高效率。 目的：实现检测页表访问位并将结果返回到用户态 前提知识 RISC-V硬件处理TLB缺失时，将新的虚拟地址载入时，会将相应的页面访问位置位 具体工作 代码实现在kernel/sysproc.c中的sys_pgaccess()，参数如下 第一个要检查的用户页面的虚拟地址 将要检查页面的数量 用于返回掩码结果的用户空间地址 使用**argaddr()和argint()**解析参数 最好在内核使用一个临时的缓冲区保存要输出的位掩码，利用copyout()输出 可以设置扫描页面数量的上限 使用walk()来找到正确的PTEs 需要在kernel/riscv.h中定义PTE_A 确保检查PTE_A后，将其清零。否则无法判断在上次检查之后该页面有没有再次被访问 使用**vmprint()**来帮助debug 代码 *"},{"title":"cs144","path":"/2023/01/30/Stanford-CS144/","content":"RISCV Chapter 4 陷阱：三种强制CPU放弃执行当前指令而执行特殊代码的事件 系统调用：软中断 异常：零除；无效的虚拟地址 设备中断：比如磁盘完成读写 从陷阱退出后，应该恢复至发生陷阱前的状态 进入陷阱，强制进入kernel kernel保存当前运行状态 kernel执行中断处理代码 kernel用保存数据恢复状态 退出陷阱，继续正常执行代码 RISC-V trap mechinery","tags":["course","cs-network","lab"],"categories":["base-course"]}]