[{"title":"聪明的投资者","path":"/2023/05/15/smart-investigator/","content":"投资与投机 确立恰当的证券组合策略是什么意思？ 投资与投机","tags":["财经理财"],"categories":["读书笔记"]},{"title":"原则","path":"/2023/05/05/principles/","content":"引言 未来的时代将与我们现在经历的时代完全不同，但在历史上的许多时代有着相似之处 大多数人类个体只是宏观世界中渺小的蚂蚁，终其一生只能埋头搬运面包屑。只有结合历史来认识现在，以更宏观的视角观测世界才能掀开未来的一角面纱，从而突破局面。 我们的世界总在和平与战争之间循环往复。和平时社会繁荣发展，但也伴随着社会财富和权利的分配不均问题。战争虽然残酷，却将世界重新洗牌，以上一次和平的发展成果烧毁为肥料，孕育一个更加繁荣的和平。 上面这样的过程，我们称为周期。世界存在很多周期，人们的生活随着周期的改变而发生巨变。我们需要认识到：从一个极端到另外一个极端并不是例外，而是世界的常态。 周期是宏大的，人生是短暂的，许多人一生只能经历一个辉煌或者一个萧条。因此历史是我们预测时期改变的重要工具，我们现在面临的未来可能与大多数人所预期的情况相差很大 一个人预测和应对未来的能力，取决于他对事物变化背后的因果关系的理解；一个人理解这些因果关系的能力，来自他对以往变化的发生机制的研究。 主要研究的三个周期 长期债务和资本市场周期：目前债务利率极低，作为储蓄货币的美元将走向何处。 内部秩序和混乱周期：贫富差距拉大，而经济增速放缓，如何应对财富分配的矛盾。 外部秩序和混乱周期：中美贸易竞争，世界格局混乱，对个人将会产生何种影响。 想要把握全局，就不能着眼于细节。请保持谦卑，你所未知的远远多于你已知的事情。 大周期简述 从古至今，权力和财富的创造、获取和分配是影响人类社会最主要的因素。所有国家都存在财富拥有者，他们为了维持和增加财富，往往与执政者合作，建立共生关系，制定和执行规则。 这样的模式会将财富和权力聚集到小部分人身上，底层人民收到巨大压迫，引发剧烈冲突，重新建立秩序。目前相对财富、权力和世界秩序正在发生典型的巨变，这将对所有国家的每个人都产生深远的影响。 人类的本性不会随时间而发生变化，贪婪、恐惧、嫉妒等等情感是驱动周期发展的重要因素 人类社会始终在进步，但是中间一直存在着周期，就像马克思所说的事务是呈螺旋上升的，这样的规律适用于所有的社会事务。生产率不断提高是人类进化所决定的必然趋势，进化的结果不断调整着价值、权力与社会结构。 但是进化带来的生产率的改变往往是缓慢的、短期难以看见的。因此短期巨大的波动都是由周期的力量来推动的。 一个良好的体系是人们提出创新想法，通过资本市场获得资金，将创新转化为生产和资源分配，从中获利而得到回报。但是，长期来看，资本注意造成了财富和机会差距，助长过度负债，导致经济衰退，引发革命和战争。进而改变了国内和世界秩序。 拥有大量储蓄、低负债和强大储备货币的国家能够更好地抵御经济和信贷崩溃。反之，则不行。 惯性是社会中永远存在的现象。当经济繁荣时，人们信心大增以至于产生金融泡沫。当经济萧条时，人们又过度担忧，导致经济进入通缩。因此理性评估市场的真实情况，不受大众情绪影响，才能够真正脱离惯性给自己带来的影响。在面对困境时，我们应该相信自己的适应能力，我们的能力永远大于我们面对的困境。 作者归纳出了财富和权力的8个决定因素：教育、竞争力、创新和技术、经济产出、世界贸易份额、军事实力、金融中心实力以及储备货币地位。其中内涵的逻辑大致如下： 教育可以推进创新和技术，进而扩大世界贸易份额和军事实力，增加经济产出，建设世界领先的金融中心，在一定时期之后，构建起作为储备货币的货币体系。 一般可以将国家分为三个阶段。第一个阶段是上升阶段，这个时期国家的基本面较为强劲。然后是顶部阶段，这个时期内部财富差距和负债拉大，国家开始发生冲突。最后是下跌阶段，充斥着各种争斗和结构性重组，从而导致严重冲突和巨大变革。 上升阶段：卓越的领导人；强大的教育实力；坚韧的性格、良好的修养和职业道德；创新和发明新科技；对全球最佳思维的开放态度；劳动者、政府和军队通力合作。这些条件会推动国家的经济发展，从而有资金投入基础设施、教育和研发之中，并且创建激励和支持机制，扶持有能力创造或者获得财富的人。然后发展资本市场将储蓄转化为投资，发展世界领先的金融，从而吸引和分配当时的资本。最后逐渐扩大国际贸易让货币变为世界主要存储货币。 顶部阶段：繁荣中隐藏危机。此时的国家强大富有，劳动者收入提高。但是随着劳动成本上升，竞争力下降，同时随着生活水平的，人们往往不再努力工作，并且会通过借贷来享受优越的生活，从而导致金融泡沫。并且随着收益分配不均，贫富差距拉大，整个体制会逐步倾向于富人，这将导致底层的仇富心理加重。 下跌阶段：经济疲弱，内部斗争严重。 从内部看，经济出现衰退，债务危机严重，政府会选择大量增发货币，国内的各种矛盾冲突严重激化，于是出现试图重新分配财富的左派，仇富心理在国内蔓延。此时，富人通常被加征税收，他们往往会选择转移财富，导致税收减少，国家就会禁止这种行为，让富人变得更加恐慌。 从外部看，当出现一个可以挑战秩序的崛起大国，通常会导致战争。一旦储备货币持有人对其货币失去信心，那么标志大周期结束，新一轮周期在战争中开始。 决定因素","tags":["视角转换，财经理财"],"categories":["读书笔记"]},{"title":"C++","path":"/2023/05/01/C++/","content":"流 标注输入输出流","tags":["编程语言"],"categories":["C++"]},{"title":"CMake","path":"/2023/05/01/Cmake/","content":"CMake","tags":["编译配置"],"categories":["C++"]},{"title":"数据挖掘","path":"/2023/05/01/Data-Mining/","content":"引论 什么是数据挖掘 数据中的知识发现（Knowledge discover in data） 数据挖掘的基本步骤： 数据清理： 删除噪声和不一致的数据 数据集成： 将多个数据源组合在一起 数据选择： 从数据库中提取出与分析任务相关的数据 数据变换： 通过汇总或聚集操作，将数据变换和统一为适合挖掘的形式 数据挖掘： 用智能方法提取数据模式 模式评估： 用某种兴趣度度量，识别真正有趣的模式 知识表示： 使用可视化和知识表示技术，向用户提供挖掘的知识 挖掘什么类型的数据 数据库数据 数据仓库 事务数据 挖掘什么类型的模式 特征化与区分 频繁模式，关联和相关性 预测分析：分类与回归 聚类分析 离群点分析 所有模式都是有趣的么？ **有趣：**非平凡的，蕴含的，潜在有用的，先前未知的 度量： 客观度量 支持度 置信度 主观度量 使用什么技术 统计学 机器学习 监督学习 无监督学习 半监督学习 主动学习 认识数据 数据对象与属性类型 **属性：**是一个数据字段，表示数据对象的一个特征。 标称属性： 一些符号或事物的名称。被视为分类的，无序的，枚举的。 二元属性：只有两个状态0或1，0表示不出现，1表示出现 对称二元属性：两种状态具有同等价值，如男性，女性 非对称二元属性：两种状态价值不同，比如病毒检测结果阳性更具价值 序数属性：值域元素之间存在有意义的序或者秩，但是排序相邻的元素之间的差值是未知的。如：大杯，中杯，小杯，我们并不知道大杯比中杯大多少，只知道这个排序。 数值属性：定量的属性，可以用整数或者实数表示，是可以区间标度的或比率标度的 区间标度：例如温度，可以说一个温度比另外一个温度高多少度。但是华氏度和摄氏度都不能说一个温度比另外一个温度高多少倍。它们只是有相同的单位尺度，但没有绝对的零点 比率标度：具有固定零点的数值属性。如：公司员工数量，货币量等等 离散属性与连续属性 数据的基本统计描述 中心度量趋势 均值： 普通均值 加权均值 截尾均值：去掉极高和极低的数据的均值 中位数： 奇数个数据： 偶数个数据： 近似中位数： 众数 一个数据集中可能有多个众数 如果每个数据仅出现一次，那么该数据集没有众数 中列数：一个数据集最大值和最小值的平均值 数据分布： 对称：中位数等于众数 非对称： 正倾斜：中位数大于众数 负倾斜：中位数小于众数 度量数据散布 极差：数据集最大值和最小值的差值 四分位数：用3个数据点将数据集划分为大小相等的4个子集，这三个数据点为四分位数。第二个四分位数为中位数。 四分位数极差：第三个四分位数减第一个四分位数，即：，表示数据中间一半覆盖的范围。 盒图： 盒体上边界为： , 下边界为： 上胡须延长至：极大值，下胡须延长至：极小值 离散点：超过四分位数1.5*IQR的数据，单独画出。 方差和标准差： 基本统计描述的图形表示 分位数图 纵轴：属性的数据范围 横轴： 分位数-分位数图 直方图 散点图 数据可视化 数据可视化的意义：通过图形清晰有效的表示数据 度量数据的相似性和相异性 数据矩阵和相异性矩阵 数据矩阵： 矩阵，n个对象，p个属性 相异性矩阵： 矩阵， 其中元素代表相异性度量 相似性度量： 标称属性的邻近性度量：, 其中p为标称属性个数，m为两对象在相同的标称属性上值相同的个数。 二元属性的邻近性度量 对称属性： 非对称属性：, 因为负负属性不重要，所以直接去掉 数值属性的邻近性度量：闵可夫斯基距离 欧几里得距离：又称L2范数 曼哈顿距离：又称L1范数 上确界距离：, 即最大差值，也称一致范数 序数属性的邻近性度量：, 将序数属性转化为数值属性进行计算 混合类型属性的相异性 只要有一个对象的属性值缺失，则,否则 f为数值属性，则： f是标称或二元，则若,则，反之为1 序数的就转化为数值属性处理即可 余弦相似性：针对文档等稀疏的词向量 数据预处理 数据预处理概述 数据质量：为什么要数据预处理 准确性： 数据是没有错误的 完整性：数据属性值是完整的 一致性：数据记录之间是没有冲突的 时效性：时间的影响 可信性：挖掘者是否信任该数据 可解释性：能知道怎么解释这个数据的意义 数据预处理的主要任务（作用） 数据清理 数据集成 数据规约 数据变换 数据清理 缺失值 忽略整个元组 人工填写 全局常量填写 中心度量填写 同一类元组的中位数或均值填充(当数据是倾斜的选择中位数) 最可能值填写：通过回归，贝叶斯，决策树等方法 噪声 分箱 箱均值光滑 箱中位数光滑 箱边界光滑 回归：通过函数拟合 离群点分析：聚类分析等方法 数据清理作为一个过程 偏差检测 元数据：属性的数据类型和定义域，均值，中位数，倾斜还是对称 字段过载 唯一性规则：值域没有重复元素 连续性规则 空值规则 数据集成 实体识别问题：两个数据源进行属性匹配，如：cus_id与cus_num 冗余和相关性分析 标称数据采用卡方检验： 数值属性的相关系数 数值属性协方差： 数据规约 数据规约概述 维规约：减少属性个数，如：小波变换，主成分分析 数量规约：用较小的数据代替元数据，如：直方图，聚类，抽样 数据压缩 有损：近似重构原数据 无损：重构后不损失信息 数据变换与数据离散化 数据变换策略概述 光滑：去掉噪声，分箱，回归，聚类 属性构造：根据已有属性，构造新的属性 聚集：对数据进行汇总和聚集，如根据月销售量聚集成年销售量 规范化： 将数据缩放进一个小区间内 离散化：数值属性的原始值用区间或标签替代 分箱 直方图 聚类、决策树、相关分析 有标称属性产生概念分层 规范化数据 最大最小规范化：映射到目标区间。 z分数规范化： 小数标定规范化：，其中j为使v最大绝对值小于1的最小整数 挖掘频繁模式、关联和相关性 性质是什么啊。反正apple算法都是重点啊，它步骤是什么啊？如何得到关联规则啊？这个这个他的优缺点啊，然后这个这个啊改进的一些思路、一些基本思想，有什么缺陷啊等等等等等说法 这个是呃第六章啊最重要的算法，没有之一啊，然后其次是f算法，它跟apple算法的区别，它的思想、它的步骤，对吧？ 这个也是有给大家布置的作业的啊优缺点啊，特别是什么？一个做这个地方我们有一个非常重要的概念，可伸缩性，对吧？所以上测试我们也有这个题目啊，可伸缩性啊。好，然后呢就是使用垂直模式挖掘的好处啊，以及使用锤子模式那种方式很简单，对吧？ 我们一共就两页PPT啊，很简单很容易掌握，对吧？ 什么时候用垂直模式挖掘它有啥好处？好，以及第六章最后一个部分模式评估，我们给大家介绍五个兴趣度度量啊，哪些是零不变的。什么叫零不变性啊？啊，不平衡笔是用来干嘛的。对吧？然后学会能够用他们来评估。好，这个是第六章、第七章。 基本概念 频繁模式：频繁出现在数据集中的模式(项集，子序列，子结构) 关联规则： 支持度：表示所有事务中A和B同时出现的占比，即： 置信度：表示事务中A和B同时出现的次数/事务中出现A的次数，即： 强规则：同时满足最小支持度阈值和最小置信度阈值。 绝对支持度：由频数作为支持度 频繁项集：出现次数超过最小支持度计数 挖掘关联规则的步骤 找出所有频繁项集 由频繁项集产生强关联规则 闭：没有真超集能够和他有相同的支持度计数 闭频繁项集：闭+频繁 极大频繁项集：没有超集是频繁项集 可伸缩性：==随着数据量的增加，数据挖掘算法的运行时间必须是可遇记的，短的和可以被接受的==。 Aprior算法 先验性质 ==频繁项集的所有非空子集也一定是频繁的== ==非频繁项集的的超集也一定是非频繁的== 步骤 连接步 剪枝步 ==缺陷：== 仍然可能产生大量候选集 可能重复扫描数据库 候选支持度计数工作量繁重 由频繁项集产生关联规则 计算置信度即可 提高Apriori算法的效率 基于散列，桶计数小于最小支持度计数的直接剔除 事务压缩 划分 抽样 频繁模式增长 对于挖掘长的频繁模式和短的频繁模式，它都具有有效性和可伸缩性，并且比Apriori算法快一个数量级。 不产生候选项 压缩数据库 不重复扫描整个数据库 哪些模式是有趣的 提升度： 若提升度大于1，则两者正相关 若提升度小于1，则两者负相关 若提升度等于1，则两者相互独立 卡方相关性分析：观测值期望值期望值，期望值 全置信度： 最大置信度： Kulczynski度量： 余弦度量： ==所有以上度量都满足0～1，且值越大联系越紧密== 零事务：不包含被考察的项集的事务。 ==除了提升度和卡方相关分析外，其余度量都是零不变度量，因为它们不受零事务影响== 高级模式挖掘 基本概念 ==负模式：如果项集X和Y都是频繁的，但很少一起出现，则项集X与Y是负相关的，且为负模式== ==稀有模式：支持度低于用户指定的支持度阈值的模式== 分类：基本概念 有监督学习，无监督学习概念 分类，数字预测概念 分类的步骤 决策树和朴素贝叶斯 过拟合 基本概念 预测问题 数值预测：回归分析是最常用的方法，例：预测一位顾客将在购物期间花多少钱。构造的模型预测一个连续值函数或有序值，这种模型称为预测器 分类：构造模型或者分类器来预测类标号 学习阶段：构建分类模型 分类阶段：使用模型预测给定数据的类标号 类标号属性：离散、无序 监督学习：分类器的学习在被告知每个训练元组属于哪个类的“监督”下学习 无监督学习：每个元组的类标号是未知的，且要学习的类的个数事先也可能是未知的 过拟合： 准确率：分类器正确分类的测试集元组所占的百分比 正元组：感兴趣的主要类的元组 负元组：其他元组 决策树归纳 基本算法： 三个参数 数据分区：元组集合 属性列表：元组属性的列表 属性选择度量：基尼指数、信息增益等 树从单个节点N开始 如果D中所有元组都同一类，则节点N变成树叶，并用该类标记它 否则调用属性选择度量来指定分裂属性和分裂点 节点N利用分裂准则标记作为节点上测试，对于分裂准则的每个输出，生成一个分支，分支中的元素由D根据分裂准则划分生成 属性A是离散值：划分准则就是某几个离散值 属性A是连续值：根据分裂点划分为两个部分，生成两个分支 属性A是离散值却必须生成二叉树：分为yes，no集合 对于结果分区递归调用函数，生成决策树。 终止条件： 分区中所有元组都属于同一类 没有剩余属性可供划分元组，使用多数表决 分支没有元组，使用D中的多数类创建一个树叶 返回决策树 属性选择度量 信息增益——越大越好 信息熵： 通过属性划分后的信息增益： 解释：通过对A的分裂后，未知信息减少了多少 划分后的信息总量： 如果处理的是连续的值那么需要选择分裂点，排序后人为划分：分裂点是两个连续值的中间值，分裂的分支数一定为2 缺点：偏向选择包含大量值的属性 增益率——越大越好 解释：以划分属性分类来计算信息熵，原来的是以最终的类别 基尼指数——越小越好 代表不纯度；代表划分子集中属于最终类的百分比； 离散属性：需要将属性划分为2个子集，考虑所有划分 **连续属性：**处理方法和信息增益一致 要求越小越好，越大越好 树剪枝 先剪枝：可以使用统计显著性、信息增益、基尼指数等度量划分的优劣，如果划分节点时低于阈值就停止划分 后剪枝：完全生长的树剪去子树。 **CART的代价复杂度剪枝算法：**用剪枝集评估代价复杂度，最小化代价复杂度为目标 C4.5悲观剪枝：不使用剪枝集而使用训练集，基于认为训练集评估准确率或错误率过于乐观 可伸缩性与决策树归纳 RainForest BOAT：树构造的自助乐观算法 **思想：**取样，精度换速度 贝叶斯分类方法 贝叶斯定理 后验概率：已知某些关于这件事条件，发生这事情的概率 先验概率：一切未知的情况下，这件事发生的概率 朴素贝叶斯分类 使后验概率最大化 类条件独立假设 如果为连续值属性： 步骤 计算每个分类的先验概率 计算不同分类下各个属性的后验概率 计算给定条件的后验概率 计算先验概率与给定条件后验概率的乘积，选择最大的分类作为最终分类 若存在零概率：拉普拉斯校准，在相应属性每个值各添加一个元组 模型评估与选择 评估分类器性能的度量 准确率： 错误率： 灵敏性,召回率： 特效性： F度量： 度量： 保持方法和随机二次抽样 交叉验证 分类：高级方法 基本概念 ==后向传播：即通过类实例标号，不断修正参数，从输出层到第一个隐藏层，最终使参数收敛== ==贝叶斯信念网络：解决朴素贝叶斯类条件独立的问题== 支持向量机：通过非线性映射，将数据映射到更高维，搜索最佳分离超平面 聚类分析：基本概念和方法 基本概念 聚类：把数据对象划分为多个组或簇的过程，使得簇内的对象具有很高的相似性，但与其他簇中的对象很不相似 聚类分析 对聚类分析的要求 可伸缩性 处理不同属性类型的能力 发现任意形状的簇 对于确定输入参数的领域知识的要求 处理噪声数据的能力 增量聚类和对输入次序不敏感 聚类高维数据的能力 基于约束的聚类 可解释性和可用性 划分准则 簇的分离性 相似性度量 聚类空间 基本聚类方法概述 划分方法 给定一个n个对象的集合，划分方法构建数据的k个分区，其中每个分区代表一个簇， 大部分划分是基于距离的，采用迭代重定位的方法 迭代重定位：把一个对象移动到另外一个组来改进划分。 缺点：计算量极大，相当于枚举，基于距离的方法只能发现球状簇 层次方法 凝聚：自底向上，最初将每个对象单独作为一个组，然后逐次合并相近的组或对象直到所有的组合并为一个组，或者满足某个终止条件 分裂：自顶向下，开始将所有对象放入一个组，每次划分为一个更小的簇，或者满足某个终止条件 缺点：一个步骤完成，就不能撤销 基于密度方法 思想：只要邻域中的密度超过某个阈值就继续增长 基于网格 划分方法 K-means：基于形心的技术 工作流程 首先随机地选择k个对象，每个对象代表一个簇的初始均值或中心 对剩下的每个对象，根据其与各个簇中心的欧式距离，分配到最近的簇 利用新分配到的对象，重新计算新的中心不断迭代 缺点 不能保证k-means收敛于全局最优解，在实践中，可能会选择不同的初始簇中心运行k-means 需要预先定义k值，即多少个簇 严重受离群点影响 K-中心点：一种基于代表对象的技术 思想：不用对象的均值作为参照点，而是用一个实际对象代表簇 误差标准： 层次方法 凝聚的与分类的层次聚类 凝聚 每个簇都用簇中所有对象代表 两个簇的相似度用不同簇中最近的数据点对的相似度来度量 算法方法的距离度量 最小距离：两个簇中距离最近的两个点的距离 如果最近的两个簇之间的距离超过阈值，聚类终止，则称其为单连接算法 最大距离：两个簇中距离最远的两个点的距离 如果当最近的两个簇之间的最大距离超过阈值，聚类终止，则称其为全来接算法 如果真实的簇较为紧凑且大小近似相等，则这种方法将会产生高质量的簇，否则毫无意义 均值距离：中心点的距离 平均距离：计算两个簇中所有点组合的距离均值 BIRCH：使用聚类特征树的多阶段聚类 应用场景：大量数值数据聚类 优点：可伸缩性，可以撤销先前步骤的工作 Chameleon：使用动态建模的多阶段层次聚类 思想：动态建模确定一对簇的相似度 优点：不用依赖于一个静态的，用户提供的模型，能够自适应 概率层次聚类 思想：通过概率模型度量簇之间的距离，克服以上某些缺点 基于密度的方法 DBSCAN：一种基于高密度连通区域的基于密度的聚类 核心对象：邻域内的对象数量大于等于阈值 邻域密度：邻域内的对象数度量 直接密度可达：该点在核心对象点邻域中 密度可达：直接密度可达传递，出发点和中间点必须是核心对象 密度相连：两个中心能够从同一个点密度可达 基于网格的方法 思想：将对象空间量化为有限数目的单元，这些单元形成了网格结构，所有的聚类操作都在该结构上进行 优点：处理速度快，处理速度进依赖于量化空间中每一维上的单元数 聚类评估 高级聚类分析 离群点检测 什么是离终点啊。离群点和其他的一些相似概念有什么区别啊？离群点点的定义啊，经典的三种离群点的分类啊，离群点检测是个什么概念啊？这样一些啊。 然后呢就是四种离群点检测的方法，他们的原理，他们的假设，特别是他们的假设是什么？原理是什么？特点是什么啊，优缺点是什么啊，然后有监督、无监督从另外一个角度来划分，有监督、无监督、半监督这种离群点检测啊，他们的概念、特点啊是什么啊？ 啊，优势。优缺点，优势是什么？适用于什么样的场景。对吧？啊，然后最后就是对于高危的触点它的挑战是什么？它的困难是什么？啊，基本思路是什么啊？挖掘情景的清点和集体的景点啊，他的思路是什么啊。这个这个对困难在什么地方？对吧？ 基本概念 离群点：显著不同于其他数据对象的数据对象 离群点和离群点分析 离群点的类型 全局离群点 显著的偏离数据中的其他对象 情景离群点 关于对象的特定情景，显著地偏离其他对象。 比如夏天-1度 集体离群点 单个点或许不是离群点，但是这群点的集合是异常点 离群点检测方法 监督半监督无监督方法 监督方法：专家标记基础数据的样本 缺点： 离群点总体数量少，专家标记样本可能不足以代表离群点分 无监督方法 假设：正常对象在某种程度上是聚类的 缺点：不属于簇的可能是噪声而不是离群点，开销大 半监督方法 高维数据中的离群点检测 挑战 离群点的解释 数据的稀疏性 数据子空间 关于维度的可伸缩性 Question 数据挖掘的功能是什么 数据挖掘的主要问题和挑战是什么 各个图的优缺点，适用场景是什么 数据可视化的意义 协方差等于0可能相关也可能无关 可伸缩性是什么 垂直模式挖掘的好处，什么时候用","tags":["数据挖掘"],"categories":["课程笔记"]},{"title":"数据结构","path":"/2023/05/01/Data-Structure/","content":"绪论 数据结构基本概念 基本概念和术语 数据：不是简单指数字，而是代指一切能够输入计算机内部的符号，并且该符号承载了信息以及事物的属性 数据元素：是一个整体结构，内部包含数据项，数据项是组成数据元素的最小单位。比如：学生（学号、姓名、班级） 数据对象：具有相同性质的数据元素的集合，如：数据库中元组和关系，元组是数据元素，关系是数据对象 数据类型 原子类型：不可再分的类型，如：基本数据类型int， double 结构类型：可再分的类型，如：struct 抽象数据类型：既有数据集合，又有对该集合操作的类型，如：类 数据结构 本质：==数据元素的集合==。集合内的数据元素之间存在特定的关系，如：树，图，链表等。简单理解，就是以什么形式(结构)组织数据元素，以适用于特定的应用场景 三要素：逻辑结构，物理结构(存储结构)，对数据元素的操作(数据运算) 数据结构三要素 逻辑结构：独立于物理存储和计算机的结构，是人为设计的抽象结构。主要分为线性结构，非线性结构 存储结构 顺序存储：物理上连续的存储，优点：占用空间小，可以随机存取 缺点：产生外部碎片 链式存储：物理上不一定连续的存储，优点：充分利用存储，不会产生碎片，缺点：指针占用额外空间，且只能顺序存取 索引存储：创建索引表辅助。优点：检索速度快，缺点：索引表占用额外空间，插入和删除需要修改索引表，增加额外开销 哈希存储：通过散列函数计算存储地址。优点：所有操作都很快。缺点：可能出现冲突，解决冲突会增加时间开销 复杂度度量 度量算法好坏的尺子 时间复杂度：随着输入规模的变化，最坏情况下的执行时间的变化趋势 渐近复杂度：关注大规模输入，重视总体变化趋势和增长速度 渐近上界()：正的常系数可视为1，低次项可省略。保守估计 渐近下界()：代表执行时间的下界。乐观估计 准确确界()：上界函数等于下界函数，代表对算法执行时间的准确估计。 复杂度分析 常数时间复杂度 对数时间复杂度 线性时间复杂度 多项式时间复杂度 指数时间复杂度 具有指数时间复杂度的算法一般没有实际意义 难解问题：没有多项式复杂度的问题 输入规模：严格定义为用以描述输入所需的空间规模 递归 分支转向是算法的灵魂 递归：函数(过程)的自我调用。简洁准确地描述问题 递归基：平凡情况。递归基能够保证递归算法的有穷性。 线性递归 简介：算法向深层递归调用，每一次至多调用自身一次，从而形成线性次序。 特征：线性递归问题，总可以分解为两个子问题，一个是独立的某个元素，另一个是和原问题结构一致的子问题。经过合并之后得到问题解。这类问题每次将问题规模缩减一个常数，最终抵达递归基，也称为减而治之 递归分析 递推方程：写出递推公式，确定平凡模式条件，结合数学归纳得出递归复杂度 递归跟踪：以图的形式刻画递归过程，从而分析递归复杂度 递归模式 多递归基 多向递归 二分递归 分而治之 将问题分解为若干规模更小的子问题 难点：需要对问题重新表述，保证子问题与原问题接口的形式一致 注意：对算法的渐近复杂度几乎无影响 分而治之适用条件 子问题划分和子问题合并这两个计算必须能够高效实现 各个子问题独立求解，并不相互依赖 优化策略 对于子问题有重合的问题，可以选择使用制表或者动态规划来进行优化 抽象数据类型(ADT) 外部特性与内部实现分离，提供一致且标准的对外接口 向量 物理存储顺序与逻辑顺序相同的数据结构 从数组到向量 向量：根据面向对象思想，对线性数组的抽象与泛化。其中的数据元素不再只是基本数据类型，也不保证每个元素都有某个数值 接口 操作接口 构造与析构 指导计算机创建和回收对象 构造函数：告诉计算机如何配置一个对象的内存 析构函数：告诉计算机如何回收一个对象的内存 动态空间管理 高效利用空间 静态空间管理：在向量的生命周期内无法改变容量 动态空间管理：在向量的生命周期内容量可以动态变化 可扩充向量：一种动态空间管理方法。申请新的更大的内存，然后复制数据，回收原来的内存 基本问题 新容量取多少：2倍原内存 分摊分析 将某些时间复杂度不确定的操作，将其所消耗的时间分摊到所有操作上 常规向量 直接引用元素 template &lt;typename T&gt; T&amp; Vector&lt;T&gt;::operator[](rank i) {return _elem[i];} 置乱算法 template &lt;typename T&gt; T&amp; Vector&lt;T&gt;::permute(rank lo, rank hi){ T* base = _elem + lo; for(int i = hi - lo; i &gt; 0; i--){ swap(base[i-1], base[rand() % i]); } } 顺序查找 template &lt;typename T&gt; rank Vector&lt;T&gt;::find(const T&amp; e, rank lo, rank hi) const{ while(lo &lt; hi-- &amp;&amp; e != _elem[hi]); return hi &lt; lo ? -1 : hi; } 插入 template &lt;typename T&gt; rank Vector&lt;T&gt;::insert(const T&amp; e, rank r){ expand(); // 必要时扩容 for(int i = _size; i &gt; r; i--) _elem[i] = _elem[i-1]; _elem[r] = e; _size++; return r; } 时间复杂度： 删除 template &lt;typename T&gt; rank Vector&lt;T&gt;::remove(rank lo, rank hi){ if(lo == hi) return 0; while(hi &lt; _size) _elem[lo++] = _elem[hi++]; _size = lo; shrink(); return hi - lo; } 时间复杂度： 唯一化 template &lt;typename T&gt; int Vector&lt;T&gt;::deduplicate(rank lo, rank hi) { int old_size = _size; if(lo == hi) return 0; for(int i = 1; i &lt; hi;){ find(_elem[i], lo, i) &lt; 0 ? i++ : remove(i); } return old_size - _size; } 有序向量 唯一化 template &lt;typename T&gt; int Vector&lt;T&gt;::deduplicate(){ int i = 0, j = 0; while(++j &lt; _size) if(_elem[j] != _elem[i]) _elem[++i] = _elem[j]; _size = i; return j - i; } 时间复杂度： 查找 二分查找 版本A template &lt;typename T&gt; rank Vector&lt;T&gt;::search(const T&amp; e, rank lo, rank hi) const{ while(lo &lt; hi) { rank mid = (lo + hi) &gt;&gt; 1; if(_elem[mid] == e) return mid; else if(_elem[mid] &lt; e) lo = mid + 1; else hi = mid; } return -1; } 版本B template &lt;typename T&gt; rank Vector&lt;T&gt;::search(const T&amp; e, rank lo, rank hi) const{ while(1 &lt; hi - lo) { rank mid = (lo + hi) &gt;&gt; 1; if(e &lt; _elem[mid]) hi = mid; else lo = mid; } return _elem[lo] == e ? lo : -1; } 版本C template &lt;typename T&gt; rank Vector&lt;T&gt;::Search(const T&amp; e, rank lo, rank hi){ while(lo &lt; hi) { rank mid = (hi + lo) &gt;&gt; 1; if(e &lt; _elem[mid]) hi = mid : lo = mid + 1; } return --lo; } 斐波那契查找 template &lt;typename T&gt; rank Vector&lt;T&gt;::fib_search(const T&amp; e, rank lo, rank hi) { Fib fib(hi - lo); while(lo &lt; hi){ while(fib.get() &gt; hi - lo) mid = fib.pre(); if(e &lt; _elem[mid]) hi = mid; else if(e &gt; _elem[mid]) lo = mid + 1; else return mid; } return -1; } 排序与下界 排序及其分类 数据处理规模或存储特点：外部排序和内部排序 数据的输入形式：离线和在线 随机策略：确定式和随机式 比较树 定义：根绝算法的比较与比对流程将算法抽象为一棵比较树 作用：估计基于比较式算法的复杂度下界 方法：根据算法可能的输出结果数量，反推比较树的最大高度，从而估计算法的复杂度下界 排序器 稳定性：排序完成后，值相同的元素在向量中的相对位置不发生改变 冒泡排序 template &lt;typename T&gt; rank Vector&lt;T&gt;::bubble_sort(rank lo, rank hi){ while(!bubble(lo, hi--)); } template &lt;typename T&gt; rank Vector&lt;T&gt;::bubble(rank lo, rank hi){ bool sorted = true; while(++lo &lt; hi){ if(_elem[lo - 1] &gt; _elem[i]){ sorted = false; swap(_elem[i], _elem[i-1]); } } return sorted; } 冒泡排序算法具有稳定性 归并排序 template &lt;typename T&gt; void Vector&lt;T&gt;::merge_sort(rank lo, rank hi) { if(hi - lo &lt; 2) return ; mid = (lo + hi) &gt;&gt; 1; merge_sort(lo, mid); merge_sort(mid, hi); merge(lo, mid, hi); } template &lt;typename T&gt; void Vector&lt;T&gt;::merge(rank lo, rank mid, rank hi) { T* A = _elem + lo; int lb = mid - lo; T* B = new T[lb]; for(int i = 0; i &lt; hi - lo; i++) B[i] = A[i]; int lc = hi - mid; T* C = _elem + mid; for(int i = 0, j = 0, k = 0; (i &lt; lb || j &lt; lc);){ if(i &lt; lb &amp;&amp; (!(j &lt; lc) || B[i] &lt;= C[j])) A[k++] = B[i++]; else if(j &lt; lc &amp;&amp; (!(i &lt; lb) || C[j] &lt; B[i])) A[k++] = C[j++]; } delete[] B; } 第一个能够在最坏情况下保证复杂度的确定性算法 时间复杂度：，即使在链表上也能保证这个时间复杂度 其中merge()时间复杂度为 列表 无序列表 特点：熟知的代表是链表，逻辑顺序和物理顺序不一定一致的数据结构。 头尾节点 作为哨兵存在，对外不可见。头节点指向首节点，尾节点的前驱指向末节点。 默认构造方法 template &lt;typename T&gt; void List&lt;T&gt;::init(){ header = new ListNode&lt;T&gt;; tail = new ListNode&lt;T&gt;; header-&gt;succ = tail; header-&gt;pred = nullptr; tail-&gt;pred = header; tail-&gt;succ = nullptr; _size = 0; } 位置代替秩 #define ListNodePos(T) ListNode&lt;T&gt;* template &lt;typename T&gt; T&amp; List&lt;T&gt;::operator[](rank r) const { ListNodePos(T) p = first(); while(r--) p = p-&gt;succ; return p-&gt;data; } 查找 #define ListNodePos(T) ListNode&lt;T&gt;* template &lt;typename T&gt; ListNodePos(T) List&lt;T&gt;::find(T const&amp;e, int n, ListNodePos(T) p) const { while(n--) if(e == (p = p-&gt;pred)-&gt;data) return p; return nullptr; } 插入 #define ListNodePos(T) ListNode&lt;T&gt;* template &lt;typename T&gt; ListNodePos(T) List&lt;T&gt;::insert_as_first(T const&amp;e){ _size++; return header-&gt;insert_as_succ(e); } template &lt;typename T&gt; ListNodePos(T) List&lt;T&gt;::insert_as_Last(T const&amp;e){ _size++; return tail-&gt;insert_as_pred(e); } template &lt;typename T&gt; ListNodePos(T) List&lt;T&gt;::insert_before(T const&amp;e, ListNodePos(T) p){ _size++; return p-&gt;insert_as_pred(e); } template &lt;typename T&gt; ListNodePos(T) List&lt;T&gt;::insert_after(T const&amp;e, ListNodePos(T) p){ _size++; return p-&gt;insert_as_succ(e); } 其中辅助函数为节点本身提供的插入函数 #define ListNodePos(T) ListNode&lt;T&gt;* template &lt;typename T&gt; ListNodePos(T) ListNode&lt;T&gt;::insert_as_succ(T const&amp;e){ ListNode&lt;T&gt; new_node = new ListNode&lt;T&gt;(e, pred, this); pred-&gt;succ = new_node; this-&gt;pred = new_node; return new_node; } template &lt;typename T&gt; ListNodePos(T) ListNode&lt;T&gt;::insert_as_pred(T const&amp;e){ ListNode&lt;T&gt; new_node = new ListNode&lt;T&gt;(e, this, succ); this-&gt;succ = new_node; succ-&gt;pred = new_node; return new_node; } 复制构造函数 #define ListNodePos(T) ListNode&lt;T&gt;* template &lt;typename T&gt; void List&lt;T&gt;::copy_nodes(ListNodePos(T) p, int n){ init(); while(n--) { insert_as_last(p-&gt;data); p = p-&gt;succ;} } template &lt;typename T&gt; List&lt;T&gt;::List(ListNodePos(T) p, int n) { copy_nodes(p, n); } template &lt;typename T&gt; List&lt;T&gt;::List(List&lt;T&gt; l) { copy_nodes(l.first(), l._size); } template &lt;typename T&gt; List&lt;T&gt;::List(List&lt;T&gt; l, rank r, int n) { copy_nodes(l[r], n); } 删除 template &lt;typename T&gt; T List&lt;T&gt;::remove(ListNodePos(T) p) { T e = p-&gt;data; (p-&gt;pred)-&gt;succ = p-&gt;succ; (p-&gt;succ)-&gt;pred = p-&gt;pred; delete p; _size--; return e; } 栈与队列 栈 特点：后进先出的线性容器。 表示：线性容器可以采用数组或者链表形式表示。 应用：① 逆序输出 ②递归嵌套 ③延迟缓冲 ④逆波兰式 算法：① 回溯法 ②八皇后 ③迷宫 接口：报告栈的规模(size)、判断栈是否为空(empty)、将元素压入栈顶(push(e))、删除栈顶元素(pop)、引用栈顶元素(top)； 代码 队列 特点： 应用： 算法： 接口： 代码 二叉树 基本概念 有根树：有根节点的树。 深度：从根节点到该定点经过的边数。 高度：从以该节点为根节点的树的所有叶子节点最大深度。 祖先：从根节点出发到该节点经过的所有节点，包括该节点。除开该节点为真祖先。 度：该节点的孩子节点数量。 真二叉树：不含1度节点的二叉树。 多叉树转二叉树：长子兄弟法，形象一点就是长兄为父。 二叉树 特点：所有节点的度不超过2的有根树，是半线性结构。 表示：① 父节点列表表示法：快速定位父节点但是定位子节点需要遍历。② 子节点向量表示法：快速定位子节点。③ 父子节点向量列表表示法：父子查询效率均不错，但是面对频繁的插入删除，成本太高。 应用：搜索 算法：哈夫曼编码、前缀无歧义树 代码 图 基础概念 简单图：不含任何自环的图，自环就是两端点是同一个顶点的边。 图 特点：（待完善修正）能够表示事务相互之间的复杂关系。 表示：① 邻接矩阵 ② 邻接表 差异：邻接矩阵表示的图，其对边的静态和动态操作都仅需要O(1)的时间复杂度，但是其对顶点的操作往往会具备O(n)的复杂度。与之相对比，邻接表表示能够节省空间，虽然会在边的操作上损失一部分性能，例如查询某条边是否存在，但是在关于边的动态操作上具备更好的性能。同时邻接表在进行批量操作时，表现更好的性能，能够在图遍历算法中提供更好的表现。所以一般选择邻接表。 应用：相互之间具有复杂关系的事务 算法：①广度优先算法 ②深度优先算法 ③ 拓扑排序算法 搜索树 高级搜索树 伸展树 特点：不需要记录额外信息或者对二叉节点进行附加调整，也不需要时刻保证树的平衡。非常简洁的同时保持了分摊下的高效。 局部性原理：刚刚被访问的数据，很可能不久后又要访问。将要被访问的数据可能出现在之前被访问数据的附近。","tags":["计算机","考研"],"categories":["基础课程"]},{"title":"GDB","path":"/2023/05/01/GDB/","content":"多线程调试","tags":["调试工具"],"categories":["C++"]},{"title":"自控力","path":"/2023/05/01/self-control/","content":"第四章 乐观是如何然我们放纵的？为什么成功自控之后往往会在另外一件事情上屈服于诱惑？ 心理学概念 道德许可：如果一个人通过一件事情自我道德感觉良好，那么他就会更愿意相信自己的直觉，认为自己的直觉是正确的。若将意志力目标绑定了道德属性，比如锻炼了定义为“好”，没有锻炼定义为“坏”，那么就更有可能今天锻炼了，而明天不锻炼。 目标释放：自控过程中，我们压抑大脑的及时行乐念头，但是当在长远目标上取得进步时，大脑会暂停思考，并尝试去满足被压抑的念头。 许可没有逻辑 许可单纯让我们做出贝利自己最大利益的事情。让我们把想做的诱惑变为必须要做的事情。道德化意志力目标，会让我们怀疑自己的目标。因为人是天生反感强加的规则的，因此道德化的目标仅仅是正确的规则，而不是我们真正实现目标的途径。 为了避免道德许可，我们要清晰区分道德和目标。 进步也是阻碍 许多人都将进步视为一种激励，但事实上除了激励，进步也会让我们放松，甚至做出摧毁进步成果的行为。在实际生活中的表现就是，当你前进一小步，会导致你后退两大步。 今天犯错，明天补救 大脑对能完成目标的可能性感到兴奋，它会错把完成任务的可能性当作已经完成任务。 剖析和实验 剖析任务 你是否有向明天赊账？你是否真的在明天真的做到弥补过错？ 实验任务 记住我们为什么会拒绝诱惑，能够有效提升自控力。 让每天尽量一样。试着减少行为的变化性，而不是减少那种行为。 第五章 多巴胺催促着你去获得让你能够感到快乐的东西，或者重复能够刺激它分泌的事情 神经生物学原理 多巴胺：一种神经递质，它在大脑中发挥着重要的调节作用。它主要参与调节运动控制、情绪、记忆、奖赏等方面的功能。其中关于奖赏，多巴胺能够帮助人们感受到奖赏的快感，促使人们追求积极的体验和行为，如食物、性行为、社交等。 多巴胺使人产生的感觉：欲望，寻觅，希望，渴望。 促进多巴胺分泌的刺激：任何让我们觉得高兴的东西或者事情 多巴胺作用模型：某件东西让你感到高兴多巴胺分泌促使去做能够获得该东西的行为重复做能够刺激多巴胺分泌的事情 正确利用多巴胺 通过将无聊的事情多巴胺化来实现正确利用多巴胺，这里的无聊的事情事情是指那些你不想做的事情。 意志力实验：将自己最不喜欢做的事情与能够刺激自己分泌多巴胺的事情结合在一起。 多巴胺的阴暗面 多巴胺既能让你获得快感，追求快乐。但是当你没有立即获得渴望的东西时也会让你感到焦虑。 个人看法 所以在生活中，有时追求一个长远的目标时，往往会导致中途屈服于一个易于获得低级诱惑，根本原因是为了缓解压力。因此，在做长远目标时，最好选择配合一个健康的短期奖励机制来缓解焦虑。 带给你快乐的是多巴胺分泌，而不一定是最终实现的目标，比如你会因购买和等待一件商品的到达而感到愉悦，但是当它真正送到你手里时，你可能都不会着急去打开它。所以我们缓解压力的办法，通常都会让我们感到更有压力 第六章 情绪低落为什么能让人屈服于诱惑呢？因为我们想要得到快乐，能够促使多巴胺分泌的事情就是最好的选择，这是人体缓解压力的机制。 神经生物学原理 压力：包括多种情绪。愤怒、悲伤、自我怀疑、焦虑等消极情绪。 调节机制：当大脑感觉到压力时，就会寻求奖励。此时多巴胺和压力将我们推向不理智的，但能短时间快乐的事情。 那又如何效应 描述了从放纵、后悔到更严重的放纵的恶性循环。当你一次又一次屈服于诱惑的时候，往往会带来更多意志力的失效。 自我谅解是打破那又如何效应的关键。自我批评会降低积极性和自控力 虚假希望综合征 有时候压力、情绪低落或许会让我们决定作出改变，因为下定决心会让我们立刻有了放松和控制感。 作出承诺，相较于坚持承诺，真正作出改变更为简单和有趣。这也是多巴胺的骗局。 剖析和实验 剖析任务 当你感到压力、焦虑或心情低落的时候，你会怎么做呢？你生气时会不会更容易受到诱惑？你是不是更难集中注意力，或者更容易拖延呢？情绪低落是如何影响你的意志力挑战的呢？ 观察什么事情引发大脑的“恐惧管理”，”恐惧管理“通常能带来诱惑和拖延。正视恐惧能够帮助你作出理性的选择。 面对意志力失效，你会责备自己吗？你会觉得这样的挫折暴露了你的贪婪、懒惰、无能等问题吗？你会感到绝望、罪恶吗？你会以挫折为借口，更加放纵自己吗？ 你只有在情绪低落时才会有动力改变吗？想想成功改变的快乐是不是你作出改变的唯一动力？你会通过幻想未来的自己来改善心情，而不是采取实际行动吗？ 实验任务 有效的解压方法：锻炼或参加体育活动、阅读、听音乐、与家人朋友相处、按摩、外出散步、冥想或者做瑜伽以及培养油创意的爱好。尝试有效的解压方法，并通过一些提示来督促自己 原理：真正能缓解压力的不是释放多巴胺或依赖奖励的承诺，而是增加大脑中改善情绪的化学物质，如血清素、催产素等。它们能够减少压力荷尔蒙，产生放松反应。 面对失败的时候从这样几个方面去思考 你感觉如何？你有什么感觉？你是否记得失败后的第一感觉？你会怎样描述那个感觉？如果是自我责备，你对自己说了什么？ 你只是凡人。每个人都会犯这样的错误。 你会跟朋友说什么？想一想如果你的好朋友经历了同样的挫折，你会怎么安慰他？你会说哪些鼓励的话？你会如何鼓励他继续追求自己的目标？ 乐观给我们动力，但是少许悲观能够帮助我们走向成功。研究发现，如果能够预测自己什么时候、会如何收到诱惑和违背承诺，你就更有可能拥有坚定的决心。在开始做一件事情前先进行预演失败，那么我们能够更好的将计划进行推进 总结 学会让自己的心态始终保持平静，深刻认识什么事情真正让自己快乐。警惕多巴胺带来的陷阱。如果真的失败，请对自己说没关系，重新开始，下一次开始前先预演一下自己可能遭遇的诱惑，能够更好地保证任务的执行。 第七章 人类会是会考虑未来各种可能性的物种，这让我们陷入出售未来的麻烦 经济学概念 延迟折扣：等待奖励的时间越长，奖励对你来说的价值越低。例如：网页刷新的网络延迟。 有限理性：在变得不理性之前，我们非常理性。 延迟满足 当我们面对即时奖励时，我们很可能会失控。想要前额皮质重新夺回控制，实现延迟满足，只需要给诱惑添加一点点距离，例如：将糖果放在抽屉里而非桌面上。 折扣率 给未来回报打折扣是人类的天性。想要摆脱这种心态，我们需要让未来变得更重要。 预先承诺的价值 预先承诺：要想实现目标，我们必须限制自己可能的选择。目的是迫使自己按照预定计划行事。 我们需要仔细分析将来可能受到诱惑的那个自己，从而设计方案来限制他。 剖析和实验 剖析任务 当你屈服于诱惑或拖延的时候，你是把哪些未来的奖励出售了？放弃抗争的即时回报是什么？长期的代价是什么？这是公平的交易吗？如果那不是理性的交易，请你去捕捉自己改变选择的时刻，是什么想法和感觉让你出售了未来？ 实验任务 面对诱惑的时候，尝试安排10分钟的等待时间。如果10分钟后你仍然想要，你就可以拥有它。这10分钟内你一定要时刻想着长远的奖励。同时可以创造一定的物理距离。 降低你的折扣率 当你受到的诱惑要做与长期利益相悖的事时，请想象一下，你为了即时的满足放弃了更好的长期奖励。 想象你已经得到了长期的奖励。想象未来的你正在享受自控的成果。 扪心自问，你愿意放弃它，来换取你短暂的快感吗？ 对未来的自己预先承诺 做好拒绝诱惑的准备(比如如果晚上打算跑步，那么白天穿上跑鞋出门)。 让改变目标变得更难(比如当你打算学习的时候就去教室，避免遭受不了打游戏的诱惑) 激励未来的自己 第八章 意志力薄弱也能传染？ 神经学概念 镜像神经元：观察周围的人的想法，感觉等，帮助我们理解其他人的经历。比如：我们看见一个人在厨房拿着菜刀，我们就知道他在做菜。或者你看见别人受伤的时候，你也会感到疼痛。 模仿 人类有模仿他人的本能。当你看到别人在做一些事情的时候，你也会跟着去做类似的事情。比如一个人在讲话的时候叉着腰，那么和他对话的人一会也大概率会叉着腰。 同样的情绪也能被模仿。当别人感到快乐或者伤心的时候，你也可能感到类似的情绪。 所以别人屈服于诱惑的时候，我们的大脑也可能屈服于诱惑。 剖析和实验 剖析任务 请对你的意志力挑战从以下角度进行评估： 在你的社交圈中是否有其他人和你有一样的意志力挑战？ 你有没有从朋友或者家人身上学到某种习惯呢？ 和某些人在一起的时候，你会不会更容易放纵自己？ 观察一下，你在模仿谁。 第九章 神经学原理 讽刺性反弹：当人们想要强调不要做一件事情的时候，往往会在大脑里强化这个事情。当疲惫、烦乱或者紧张的时候，效应更严重。 大脑将“不要做”分为两个指令，分别为避免做那件事，这称为“操作”，以及通过寻找那件事来判断你有没有在做那件事，称为’监控“。”操作“需要清晰的头脑和充沛的精力来控制，而监控则不需要。当你疲惫时，不断的监控会促使你去寻找那件事，这就可能让你去做那件你不要做的事情。 避免讽刺性反弹 避免自我内耗的最佳方法，就是坦然面对。正视自己的想法，不是压制它，而是告诉自己that's all right，我无法避免想这件事就算了，目前先做自己应该做的事情。 剖析和实验 剖析任务 你是否想忘记一些东西，是否存在讽刺性反弹效应。","tags":["个人成长"],"categories":["读书笔记"]},{"title":"逆全球化视角","path":"/notes/230713s.html","content":"观点记录 任何的技术创新在某些环节中都是由资金来决定的。技术人员只是参与其中的一环，真正的决定性因素是钱。 钱多钱少钱贵钱便宜。 美债利差是全球资金的成本。 借便宜的钱赚高息的回报。 现金并不只是存在银行里的钱。 国有企业股的核心是什么？ 科技创新是什么？ 有些路是在无形的手的引导下形成的？ 投资的精髓是负债，如何负更多的债务，如何负更多低成本的债务。一边考虑负债，一边考虑资产 未来5-10年是加完杠杆还债阶段，低通胀低利率低增长 通胀和利率是社会大部分人的情况，过去中国高通胀高利率，美国低通胀低利率 高储蓄低杠杆，人生机会 美元降息～美元借贷利差，然后借美元换人民币，啥也不干也赚，更赚的是将钱投入 首先得有居民，其次得有杠杆率"},{"title":"C++网络编程","path":"/notes/Network-Programming.html","content":"Unix哲学——万物皆文件 套接口 流式套接口stream socket 可靠的，面向连接的套接口 报式套接口datagram socket 无连接的套接口 注意 TCP协议允许在传输层对数据进行分段，而UDP则不会，UPD会在发送前在主机上完成分段操作 字节序和数据结构 字节序 大端序：低字节存高位数据，高字节存低位数据 小端序：低字节存地位数据，高字节存高位数据 网络序：网络中采用大端序 数据结构 套接口描述符：本质上就是文件描述符，符合Linux的设计哲学，类型是整型。 struct addrinfo struct addrinfo { int ai_flags; /* Input flags. */ int ai_family; /* Protocol family for socket. */ int ai_socktype; /* Socket type. */ int ai_protocol; /* Protocol for socket. */ socklen_t ai_addrlen; /* Length of socket address. */ struct sockaddr *ai_addr; /* Socket address for socket. */ char *ai_canonname; /* Canonical name for service location. */ struct addrinfo *ai_next; /* Pointer to next in list. */ }; ai_flag：用于标识 getaddrinfo() 函数返回结果的标志字段，可以设置为以下常量之一或它们的按位或组合。其中AI前缀表示Address Information AI_PASSIVE：用于指定用于套接字的地址是通配地址，适用于服务器端程序，表示服务器端将监听所有可用的网络接口。 AI_CANONNAME：用于指定返回的主机名是否是规范名，如果设置了该标志，则 getaddrinfo() 会将主机名转换为其规范名，否则返回的主机名可能是别名。 AI_NUMERICHOST：用于指定主机名必须是一个 IP 地址字符串，而不是一个主机名，如果指定了该标志，则 getaddrinfo() 不会尝试解析主机名。 AI_NUMERICSERV：用于指定服务名必须是一个端口号字符串，而不是一个服务名，如果指定了该标志，则 getaddrinfo() 不会尝试查找服务名。 AI_ADDRCONFIG：用于指定只返回与本地系统的地址族相匹配的地址，例如 IPv4 地址族的系统将只返回 IPv4 地址。 AI_V4MAPPED：用于指定如果没有找到与查询参数完全匹配的 IPv6 地址，那么getaddrinfo()将尝试返回一个 IPv4 映射的 IPv6 地址。 ai_family：表示协议类别，AF_INET表示IPV4，AF_UNSPEC表示自动判定 ai_addr struct sockaddr { unsigned short sa_family; // address family, AF_xxx char sa_data[14]; // 14 bytes of protocol address }; 通常采用它的等价结构体 struct sockaddr_in { short int sin_family; // Address family, AF_INET unsigned short int sin_port; // Port number struct in_addr sin_addr; // Internet address unsigned char sin_zero[8]; // 與 struct sockaddr 相同的大小 }; sin_addr // Internet address (a structure for historical reasons) struct in_addr { uint32_t s_addr; // that&#39;s a 32-bit int (4 bytes) }; 函数 inet_pton(family, \"IP address\", &amp;(struct sa.in_addr))：将字符串形式的IP地址转化为字节流存储 inet_ntop(family, &amp;(struct sa.in_addr), buffer'address,len)：将字节流形式的IP地址转化为字符串存储 系统调用 getaddrinfo(...) 前身是用来做DNS查询的gethostbyname() #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netdb.h&gt; int getaddrinfo(const char *node, // 例如： &quot;www.example.com&quot; 或 IP const char *service, // 例如： &quot;http&quot; 或 port number const struct addrinfo *hints, struct addrinfo **res); hints-&gt;flags：设置为AI_PASSIVE代表将绑定至本机IP，作为监听套接口 res：返回结果 示例代码 int status; struct addrinfo hints; struct addrinfo *servinfo; // 将指向结果 memset(&amp;hints, 0, sizeof hints); // 确保 struct 为空 hints.ai_family = AF_UNSPEC; // 不用管是 IPv4 或 IPv6 hints.ai_socktype = SOCK_STREAM; // TCP stream sockets // 准备好连接 status = getaddrinfo(&quot;www.example.net&quot;, &quot;3490&quot;, &amp;hints, &amp;servinfo); // servinfo 现在指向有一个或多个 struct addrinfos 的链表 我一直说 serinfo 是一个链表，它有各种的地址资料。让我们写一个能快速 demo 的程序，来呈现这个资料。这个小程序 [18] 会打印出你在命令行中所指定的主机 IP address： ** showip.c -- 顯示命令列中所給的主機 IP address */ #include &lt;stdio.h&gt; #include &lt;string.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netdb.h&gt; #include &lt;arpa/inet.h&gt; #include &lt;netinet/in.h&gt; int main(int argc, char *argv[]) { struct addrinfo hints, *res, *p; int status; char ipstr[INET6_ADDRSTRLEN]; if (argc != 2) { fprintf(stderr,&quot;usage: showip hostname &quot;); return 1; } memset(&amp;hints, 0, sizeof hints); hints.ai_family = AF_UNSPEC; // AF_INET 或 AF_INET6 可以指定版本 hints.ai_socktype = SOCK_STREAM; if ((status = getaddrinfo(argv[1], NULL, &amp;hints, &amp;res)) != 0) { fprintf(stderr, &quot;getaddrinfo: %s &quot;, gai_strerror(status)); return 2; } printf(&quot;IP addresses for %s: &quot;, argv[1]); for(p = res;p != NULL; p = p-&gt;ai_next) { void *addr; char *ipver; // 取得本身地址的指针 // 在 IPv4 与 IPv6 中的栏位不同： if (p-&gt;ai_family == AF_INET) { // IPv4 struct sockaddr_in *ipv4 = (struct sockaddr_in *)p-&gt;ai_addr; addr = &amp;(ipv4-&gt;sin_addr); ipver = &quot;IPv4&quot;; } else { // IPv6 struct sockaddr_in6 *ipv6 = (struct sockaddr_in6 *)p-&gt;ai_addr; addr = &amp;(ipv6-&gt;sin6_addr); ipver = &quot;IPv6&quot;; } // convert the IP to a string and print it: inet_ntop(p-&gt;ai_family, addr, ipstr, sizeof ipstr); printf(&quot; %s: %s &quot;, ipver, ipstr); } freeaddrinfo(res); // 释放链表 return 0; } 结果 $ showip www.example.net IP addresses for www.example.net: IPv4: 192.0.2.88 $ showip ipv6.example.com IP addresses for ipv6.example.com: IPv4: 192.0.2.101 IPv6: 2001:db8:8c00:22::171 socket(...) 是一个系统调用，返回套接口描述符 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int socket(int domain, int type, int protocol); domain：协议家族，PF_INET或者PF_INET6 type：socket的种类 protocal：传输层协议 int s; struct addrinfo hints, *res; ... // 运行查询 getaddrinfo(&quot;www.example.com&quot;, &quot;http&quot;, &amp;hints, &amp;res); s = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); bind(...) 将socket绑定到指定的IP地址和端口号上 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int bind(int sockfd, struct sockaddr *my_addr, int addrlen); socfd：套接字描述符 myaddr：getaddrinfo(...)返回的res中的res-&gt;ai_addr addrlen：getaddrinfo(...)返回的res中的res-&gt;ai_addrlen 示例代码 struct addrinfo hints, *res; int sockfd; // 首先，用 getaddrinfo() 载入地址结构： memset(&amp;hints, 0, sizeof hints); hints.ai_family = AF_UNSPEC; // use IPv4 or IPv6, whichever hints.ai_socktype = SOCK_STREAM; hints.ai_flags = AI_PASSIVE; // fill in my IP for me getaddrinfo(NULL, &quot;3490&quot;, &amp;hints, &amp;res); // 建立一个 socket： sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); // 将 socket bind 到我们传递给 getaddrinfo() 的 port： bind(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen); connect(...) 连接远端主机 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int connect(int sockfd, struct sockaddr *serv_addr, int addrlen); socfd：套接字描述符 serv_addr：getaddrinfo(...)返回的res中的res-&gt;ai_addr addrlen：getaddrinfo(...)返回的res中的res-&gt;ai_addrlen 注意：kernel 会帮我们选择一个 local port，因此一般客户端连接的时候不用bind(...) 示例代码 struct addrinfo hints, *res; int sockfd; // 首先，用 getaddrinfo() 载入 address structs： memset(&amp;hints, 0, sizeof hints); hints.ai_family = AF_UNSPEC; hints.ai_socktype = SOCK_STREAM; getaddrinfo(&quot;www.example.com&quot;, &quot;3490&quot;, &amp;hints, &amp;res); // 建立一个 socket： sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); // connect! connect(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen); listen(...) 更改此套接口的状态为监听状态 int listen(int sockfd, int backlog); backlog：代表连接此套接口队列的最大长度 一般调用顺序 getaddrinfo(); socket(); bind(); listen(); /* accept() 从这里开始 */ accept(...) 创建一个新的socket来处理进行对话 #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); addr：存放连接？？？ 示例代码 #include &lt;string.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/in.h&gt; #define MYPORT &quot;3490&quot; // 使用者将连接的 port #define BACKLOG 10 // 在队列中可以有多少个连接在等待 int main(void) { struct sockaddr_storage their_addr; socklen_t addr_size; struct addrinfo hints, *res; int sockfd, new_fd; // !! 不要忘了帮这些调用做错误检查 !! // 首先，使用 getaddrinfo() 载入 address struct： memset(&amp;hints, 0, sizeof hints); hints.ai_family = AF_UNSPEC; // 使用 IPv4 或 IPv6，都可以 hints.ai_socktype = SOCK_STREAM; hints.ai_flags = AI_PASSIVE; // 帮我填上我的 IP getaddrinfo(NULL, MYPORT, &amp;hints, &amp;res); // 产生一个 socket，bind socket，并 listen socket： sockfd = socket(res-&gt;ai_family, res-&gt;ai_socktype, res-&gt;ai_protocol); bind(sockfd, res-&gt;ai_addr, res-&gt;ai_addrlen); listen(sockfd, BACKLOG); // 现在接受一个进入的连接： addr_size = sizeof their_addr; new_fd = accept(sockfd, (struct sockaddr *)&amp;their_addr, &amp;addr_size); // 准备好与 new_fd 这个 socket descriptor 进行沟通！ ... send(...) &amp; recv(...) 和远端主机通信 int send(int sockfd, const void *msg, int len, int flags); msg：发送的信息 len：发送的长度 flags：一般设置为0即可 注意：send(...)只会尽量将资料送出，并认为你之後会再次送出剩下没送出的部分，因此它不能保证送完数据 示例代码 char *msg = &quot;Beej was here!&quot;; int len, bytes_sent; len = strlen(msg); bytes_sent = send(sockfd, msg, len, 0); int recv(int sockfd, void *buf, int len, int flags); buf：接收消息的缓冲区 len：发送的长度 flags：一般设置为0即可 注意： recv(...)会返回 0，这表示远端主机已经关闭了连接 高等技术 阻塞 阻塞就是线程在某一条语句中sleep #include &lt;unistd.h&gt; #include &lt;fcntl.h&gt; sockfd = socket(PF_INET, SOCK_STREAM, 0); fcntl(sockfd, F_SETFL, O_NONBLOCK); fcntl：使阻塞函数成为非阻塞函数 select(...) 同时监听多个套接口 #include &lt;sys/time.h&gt; #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; int select(int numfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);"},{"title":"基金基础","path":"/notes/funds.html","content":"如何分析一支基金 基金的投资策略：基金的投资策略会影响基金的风险和收益水平，因此投资者应该了解基金的投资方向和策略。例如，一些基金可能采取价值投资、成长投资、指数跟踪等不同的投资策略，不同的策略可能带来不同的投资风险和回报。 基金的历史表现：基金的历史表现可以反映出基金的投资能力和风险水平，因此投资者应该关注基金的历史表现。可以通过查看基金的过去一年、三年、五年或更长时间的表现，了解基金的平均年回报率、波动率和风险调整收益等指标。 基金管理团队：基金的管理团队会对基金的投资策略和业绩产生重要影响，因此投资者应该关注基金管理团队的资历和经验。可以查看基金管理人员的履历和过去的投资表现，以了解其投资风格和能力。 基金费用：基金的费用会对投资收益产生影响，因此投资者应该关注基金的费用情况。包括管理费、销售服务费、赎回费等各种费用。通常来说，费用较低的基金更有可能获得较高的投资收益。 市场环境：市场环境会对基金的投资表现产生影响，因此投资者应该了解当前市场环境和趋势。例如，如果当前市场处于牛市阶段，那么股票型基金可能表现较好；如果当前市场处于熊市阶段，那么债券型基金可能更适合投资。 基金规模和流动性：基金规模和流动性会影响基金的投资能力和风险水平，因此投资者应该了解基金的规模和流动性情况。一般来说，较大规模的基金通常能够分散投资风险，而流动性较好的基金则更容易买卖 基本概念 指数：股票市场中引入指数的目的就是衡量某一个集体的发展水平，可以理解为平均数 创业板： 投资准则 保持冷静、理性，不能盲目追求高收益或跟风炒作，要做好风险管理和控制，选择适合自己的投资方式和风险承受能力 投资目标指的是投资者希望通过投资达成的特定目标或目的。这些目标可能包括财务自由、退休金、子女教育、购房、旅行等。每个人的投资目标都不同，因此需要制定个性化的投资策略以实现自己的目标。 而风险偏好则指的是投资者在面对风险时所表现出的态度和偏好。风险偏好通常与投资者的投资目标、年龄、收入和资产负债状况等因素有关。通常来说，风险偏好高的投资者更愿意承担高风险高回报的投资，而风险偏好低的投资者则更倾向于保守稳健的投资。 理性的投资者应该在确定自己的投资目标和风险偏好后，选择适合自己的投资产品和投资策略，以实现自己的财务目标。例如，如果一个投资者的目标是退休金，而他的风险偏好较低，那么他可以选择投资低风险的债券基金或稳健型混合型基金来实现目标。而如果一个投资者的目标是长期资产增值，他的风险偏好较高，那么他可以选择投资高风险的股票基金或成长型混合型基金。 基金定投 进行基金定投前，可以按照以下步骤对基金进行科学客观的评估和选择： 确定投资目标和风险偏好：首先需要确定自己的投资目标和风险偏好，根据自己的需求和风险承受能力来选择基金。 考虑基金类型和投资策略：了解不同基金类型和投资策略的特点和优势，选择符合自己需求和风险偏好的基金。 查看基金的业绩表现：查看基金的历史业绩表现，特别是长期表现，以了解基金的投资能力和风险控制能力。可以通过一些金融网站或移动应用来查询基金的历史表现数据。 分析基金的投资组合：了解基金的投资组合和持仓结构，特别是其投资重点和风险分散情况，以判断其是否符合自己的投资需求和风险偏好。 查看基金的费用：基金的管理费用和销售费用对收益会有影响，因此需要查看基金的费用情况，尽量选择费用较低的基金。 选择权威的基金公司：选择一家有较强实力、声誉好的基金公司，以保障基金的安全性和稳定性。 同时，可以通过学习投资基础知识、关注市场动态、参考专业机构的分析报告等方式提升自己的投资能力。建议初学者可以阅读一些投资理论、基金投资教材、金融网站等，逐步了解和掌握基本的投资知识和技能。 作为风险偏好者，您可能更愿意承担更高的投资风险以获取更高的回报。因此，您可以考虑选择一些更加具有潜力和高风险的基金，例如： 成长股基金：这种基金主要投资于成长潜力较高的公司，这些公司可能还处于初创或快速增长阶段，但同时也具有更高的风险。 行业基金：这种基金主要投资于某个特定行业的股票，如科技、医疗等，因此也具有更高的风险。 新兴市场基金：这种基金主要投资于新兴市场国家的股票市场，如中国、印度、巴西等，这些市场具有更高的波动性和不确定性。 需要注意的是，这些基金风险更高，但同时也具有更大的潜力，需要根据您的投资目标和风险偏好做出权衡。此外，在选择基金时还应该考虑投资时间、费用、基金经理、基金公司等因素。"},{"title":"首页","path":"/notes/index.html","content":"你好，这是我的笔记"},{"title":"摄影笔记","path":"/notes/photography.html","content":"取景 基础知识 焦距决定相机取景范围。焦距越短，视野越广；焦距越长，视野越小。 因此拍摄的题材可以在一定程度上决定焦距的范围： 大场景，如建筑、风景等，适合用短焦距(28mm以下)。 人文题材适合用一般广角(35mm)，因此这个焦距也称为”人文眼“。55mm焦距也可以用来拍摄人文题材。 近距离拍摄人像、特写等场景，就更适合55、85mm焦距。这个焦距被称为“人像眼“。 透视就是常说的“近大远小”。一般来说离物体越近，透视效果越明显，也就是照片的空间感更足。 如何取景 取景范围的确定：首先确定自己想要表达的核心情感和体验。接着确定表现这种感情的主体实景，从而限定出一个小的取景范围。然后可以尝试扩大取景范围，原则：新加入的元素不影响主题的表达，至少不影响情感的表达。 取景角度的确定：根据想要实现的效果，结合透视原理来选取角度；用角度来决定画面中的元素。 取景时机的确定：若觉得画面太空，可以等待合适的元素进入。"},{"title":"如何做好Presentation","path":"/notes/pre.html","content":"什么是好的Pre 好的Pre应该是一场沉浸的故事会。将你的Pre设计成故事的形式能够带领你的观众进入你的世界观之中，帮助观众真正理解你的idea。同时，在保证故事性的同时，你应该仍然保证你的专业性，二者并不冲突。记住Pre的目的是：I want you to feel what I feel. 设计故事线 像设计剧情一样设计你的Pre故事线。你的故事将包含多幕剧情，例如：背景介绍、矛盾冲突、解决方案。在每一幕中还可以设置更小的转折点来推翻、补充、延伸之前的想法。 丰富内容"},{"title":"杂记","path":"/notes/trifles.html","content":"未分类问题 homebrew下载软件包速度缓慢的解决方案 通过homebrew来下载软件包的时候，下载速度很缓慢。我尝试过更换国内源（中科大源），但是效果仍然很差。最终通过终端代理实现提速，下载速度极快，足够满足需求。 终端代理开启命令和效果因人而异，取决于您的代理客户端和机场速度。 若您是Clash用户，那么可以通过如下操作进行： 首先复制终端代理命令。 接着在终端执行代理命令即可。 华为手机去除APP名称的解决方案 目前市场上绝大部分手机能够修改默认桌面启动器，但是华为禁止该项功能，官方解释为处于安全和隐私考虑。但这对于有定制化需求的用户来说不够合理，比如本人就想将手机上的APP名称给删除，华为系统没有该功能的实现。 因此，下面将记录通过修改华为手机主题文件来实现隐藏应用名称的方法。同时以我目前的了解来讲，很多定制化需求都能通过修改主题文件来实现，读者可自行学习。 首先下载合适的主题。 注意：请不要在华为商城下载主题，除开付费缺点外，主题出于版权是不开放源码的，无法进行修改，可以在华为或者荣耀的论坛上下载免费主题。 将下载的hwt文件解压。 注意：hwt文件是华为的主题文件，本质上是zip文件，将其后缀改为.zip即可解压。 解压其中com.huawei.android.launcher文件。 修改其中的theme.xml文件。 修改后，将之前解压的文件倒序压缩，恢复为hwt文件。 在手机上将该hwt文件放在Huawei/Themes文件夹下。 最后在华为的主题中找到新主题，应用即可。 下面是修改代码的示例： &lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt; &lt;hwthemes&gt; &lt;!-- 桌面图标投影 --&gt; &lt;color name=&quot;icon_shadow&quot;&gt;#00000000&lt;/color&gt; &lt;!-- 一键清理字体颜色 --&gt; &lt;color name=&quot;widget_text_color&quot;&gt;#FFFFFFFF&lt;/color&gt; &lt;!-- 鸿蒙卡片App文字颜色 --&gt; &lt;color name=&quot;workspace_app_text_color&quot;&gt;#00000000&lt;/color&gt;（桌面无字前两位色值加00） &lt;!--桌面图标文字投影颜色--&gt; &lt;color name=&quot;workspace_app_text_shadowColor&quot;&gt;#00000000&lt;/color&gt; &lt;!-- 桌面图标文字投影颜色 --&gt; &lt;color name=&quot;icon_shadow&quot;&gt;#00000000&lt;/color&gt; &lt;!-- 桌面图标文字阴影开关 --&gt; &lt;!-- true为显示false为隐藏 --&gt; &lt;bool name=&quot;workspace_app_text_shadow&quot;&gt;true&lt;/bool&gt;（一键清理统一色值则选择true） &lt;!-- 文件夹内APP文字颜色 --&gt; &lt;color name=&quot;folder_app_text_color&quot;&gt;#00000000&lt;/color&gt;（文件夹无字前两位色值加00） &lt;/hwthemes&gt; 注意：当您在修改代码时，完全复制本段代码，仅需要将您文件中含text的元素设置颜色为#00000000"},{"title":"Copy-On-Write","path":"/wiki/MIT-6.S081/copy-on-write.html","content":"实现写时复制 背景：fork()将父进程的所有内存复制到子进程，如果父进程占用内存很大那么复制将会十分耗时，而且如果子进程在调用fork()后，直接调用exec()那么之前所做的复制都是无效的工作，这是对CPU资源的浪费。 任务 修改uvmcopy()将父进程的物理页面映射到子进程的页表之中。同时将父进程和子进程页表的PTE均设置为只读。 修改usertrap()识别COW页面的缺页异常，触发时通过kalloc()给子进程分配物理页面，并复制父进程内容，修改PTE_W 确保对没有被任何进程的页表所引用的页面进行回收。可以通过给每个物理页面记录一个reference count。当kalloc()时将reference count设置为1，当reference count为0时，kfree()才会回收页面。可以使用一个固定大小的整型数组来存储reference count，但是必须计算出合理的数组大小，并设计合理的索引方式。例如，你可以将物理页面地址除以4096作为索引，并通过最高的物理地址来计算出数组的大小。 修改copyout()进行复制，就像遇到缺页异常一样。 提示 使用RSW位来记录一个页面是否是COW映射 在kernel/riscv.h中定义了对你有帮助的宏和页表标识位。 当一个COW页面发生缺页异常，如果此时没有多余的内存，那么选择将该进程杀死。 代码 trap.c else if((PTE_FLAGS(*(walk(p-&gt;pagetable, r_stval(), 0))) &amp; PTE_COW) != 0) { // cow handler if(cow_handler() == -1) p-&gt;killed = 1; } ... ... ... // allocate page for cow mapping // and copy the content from // old page. int cow_handler(){ char* mem; uint64 pa; pte_t* pte; uint flags; pte = walk(pagetable, va, 0); pa = PTE2PA(*pte); // check the pin count int pin = pin_count[INDEX(pa)]; if(pin == 2) { *pte &amp;= ~PTE_COW; *pte |= PTE_W; } if(pin &gt; 2) { // auquire a page size mem if((mem = kalloc())==0) goto err; // remap flags = PTE_FLAGS(*pte); flags = (flags &amp; ~PTE_COW) | PTE_W; memmove(mem, (void*)PTE2PA(*pte), PGSIZE); uvmunmap(pagetable, PGROUNDDOWN(va), 1, 1); if(mappages(pagetable, PGROUNDDOWN(va), PGSIZE, (uint64)mem, flags) != 0){ kfree(mem); goto err; } } return 0; err: return -1; } riscv.h #define PTE_COW (1L &lt;&lt; 8) // 1 -&gt; this is a cow mapping #define INDEX(a) ((a-KERNBASE)&gt;&gt;12) defs.h // vm.c pte_t* walk(pagetable_t, uint64, int); vm.c int mappages(pagetable_t pagetable, uint64 va, uint64 size, uint64 pa, int perm) { ... // reference count up if(pa &gt;= KERNBASE) pin_count[INDEX(pa)] += 1; ... } // Remove npages of mappings starting from va. va must be // page-aligned. The mappings must exist. // Optionally free the physical memory. void uvmunmap(pagetable_t pagetable, uint64 va, uint64 npages, int do_free) { ... // reference count minus 1 uint64 pa = PTE2PA(*pte); if(pa &gt;= KERNBASE) pin_count[INDEX(pa)] -= 1; if(do_free &amp;&amp; pin_count[INDEX(pa)] == 1){ kfree((void*)pa); } *pte = 0; ... } // Given a parent process&#39;s page table, copy // its memory into a child&#39;s page table. // Copies both the page table and the // physical memory. // returns 0 on success, -1 on failure. // frees any allocated pages on failure. int uvmcopy(pagetable_t old, pagetable_t new, uint64 sz) { ... // set the pte read only *pte &amp;= ~PTE_W; *pte |= PTE_COW; flags = PTE_FLAGS(*pte); if(mappages(new, i, PGSIZE, (uint64)pa, flags) != 0){ goto err; } ... } // Copy from kernel to user. // Copy len bytes from src to virtual address dstva in a given page table. // Return 0 on success, -1 on error. int copyout(pagetable_t pagetable, uint64 dstva, char *src, uint64 len) { ... if(*pte &amp; PTE_COW) cow_handler(pagetable, dstva); ... } 代码思路 本次实验是实现写时复制操作，本身逻辑比较清晰。 首先，在usertrap()中检查COW页面异常。在实现写时复制前，每个物理页面都只映射到唯一进程的地址空间之中，当修改uvmcopy()后，会出现一个物理页面映射到多个进程的地址空间的情况，因此此时会出现r_scause()==15的错误，该错误代表写指令造成的页面错误。 在usertrap()检测COW页面错误后，需要对这个错误进行处理。这里我选择单独写一个cow_handler()来处理错误，之所以这样决定是因为copyout()函数是通过walk()来访问页表，并不会引发硬件页表错误，因此也需要在copyout()中检测并并处理COW页面。因此，单独写一个cow_handler()能够实现代码复用，简化程序逻辑。 在总结cow_handler()处理逻辑前，我想先讲讲对页面引用计数的逻辑。我认为一个页面的引用计数应该和页面映射和解除映射这两个操作绑定，而不是和kalloc和kfree这两个操作绑定。因为只有当一个页面真正映射到了进程之中时，它的引用数才会增加。所以我将引用计数的更新操作放在映射和解映射操作中，以将这两个操作绑定，简化处理逻辑。 接下来，介绍cow_handler()的处理逻辑：检查物理页面的引用数，如果引用数为2，说明除了内核页表外只有一个进程的页表引用了这个物理页面，这种情况只需要将PTE的权限修改即可。如果引用数大于2，那么说明除内核外有多个进程引用了该物理页面，所以需要复制改物理页面，解除旧物理页面到该进程地址空间的映射，将新物理页面映射到该进程的地址空间中，并设设置正确的访问权限标识位。 实验总结 以上思路是很简洁明了的，代码可以很迅速写完。但是在调试过程中，这次实验给我带来了很多收获： 写代码之前，需要理清逻辑，画好流程图。这一步还是很重要的，没有流程图思路就会比较混乱，这次先画了流程图，写代码就很清晰。但是需要注意，流程图中的逻辑一定要正确，比如我在写回收页面的判断条件的时候，最初确定的是pin==1，这就忽略了内核在初始化的时候会进行一次映射，所以正确的判断应该是pin==2。 对于流程图中的每个模块的具体实现，需要仔细审视，确定每一步操作之间的依赖关系。这个相当重要，在最初的实现之中我想着就是解除映射，修改权限标志位，然后重新映射，复制页面就没问题了，操作的顺序就没有仔细考虑。这就导致调试了相当长的时间，而且觉得这段代码没有问题。事实上，在我的实现中，这4个操作之间是有相对依赖的。如果按照我错误的顺序来做，解除映射会将进程的PTE设置为0，然后我在该PTE权限基础上添加写权限和将PTE_COW位置0，所以得到了错误的权限，因为其他位都是0。而我的逻辑仍然是该flags代表了父进程的标志位。然后用错误的权限将新的物理页面映射到进程地址空间。接着的内存复制的源物理地址也依赖于PTE，此时PTE对应的物理页面已经修改为了新的物理页面，因此这段命令是原地复制。 因此，明确指令间的依赖关系是很重要的，当感觉指令顺序可以随意调换的时候，最好慎重考虑一下。"},{"title":"中断和设备驱动","path":"/wiki/MIT-6.S081/drivers-interrupts.html","content":"中断是硬件请求CPU处理的机制，驱动是操作系统中与设备交互的程序 硬件 外设：在主板上的各种芯片，以及可以连接到主板的各种设备 PLIC：中断管理设备，负责分发中断信号。接收多个设备的中断信号将其映射为对应的中断号，然后将中断号传给CPU核心，CPU核心根据中断号执行相应的中断处理程序。 PILC具体处理流程 PLIC会通知当前有一个待处理的中断 其中一个CPU核会Claim接收中断，这样PLIC就不会把中断发给其他的CPU处理 CPU核处理完中断之后，CPU会通知PLIC PLIC将不再保存中断的信息 中断 仍然利用TRAP机制实现，与系统调用和缺页异常采用同一种机制实现。但是仍然存在一些差异 异步：中断和当前运行在CPU上的进程没有任何关系。而系统调用需要保存进程上下文。 并发：产生中断的外设和CPU是相互独立，同时运行的，是真正的并行运行。例如网卡和CPU 对设备编程：中断需要对设备进行编程，控制设备操作。 所有外设都连接到CPU上，通过PLIC(Platform Level Interrupt Control)来管理设备中断，路由中断到某个CPU核心 中断相关寄存器 SIE：不同的位针对不同中断的使能。分别针对外部设备中断，软件中断使能以及定时器中断使能。 SSTATUS：控制所有中断的使能。SIE和SSTATUS在每个CPU核中都有。 SIP：发生中断时，保存中断类型。 SCAUSE：保存陷阱的类型 STVEC：保存程序计数器，保证中断、缺页异常或者系统调用结束后，程序能够继续正常执行。 驱动 定义：管理内核的代码就是驱动，驱动都在内核中。 架构：驱动的架构一般分为top和bottom两个部分，top的代码负责CPU请求设备的操作，bottom的代码负责设备请求CPU的操作。其中bottom一般是中断处理程序，当某个CPU核心接收中断就会调用该程序。top是提供给用户进程或内核其他部分程序调用的接口，例如read()和write()。 读写：内核驱动中包含存储数据的buffer，无论是top还是bottom中的程序都可以对其进行读写。驱动代码只需要与buffer进行互动，外设也只需要与buffer互动，从而相互解耦。 设备编程 通过I/O端口映射，主板厂商将设备映射到物理地址上，便可以用与读写内存相同的方式对设备进行编程，虽然这些设备并非真实存在RAM中。 启动过程 main文件 mian方法第一个函数调用consoleinit()初始化控制台。初始化包括，配置控制台的UART并设置控制台驱动top部分的读写函数。此时只是将控制台配置好，能够产生中断了，但是产生的中断并不能够被CPU感知，因为负责分配中断给CPU的PILC还没有初始化。 main方法后面会初始化PILC。在pilcinit()中配置PILC能够响应哪些设备产生的中断。 main方法最后会调用scheduler()函数来设置不同CPU会响应哪些中断。"},{"title":"文件系统","path":"/wiki/MIT-6.S081/filesystem.html","content":"文件系统为用户提供了何种抽象？这种抽象为用户提供了哪些服务？需要使用哪些机制来保证这些服务的正常运行？ 文件系统的功能 文件系统是为组织和存储数据而设计的，通常具备共享性和持久化的性质。文件系统解决如下问题： 需要特殊的数据结构来表示目录文件树、记录每个文件使用的磁盘块的标示号和空闲磁盘块。该数据结构存储在磁盘上。 需要能够在崩溃后进行恢复。当文件系统正在进行更新操作的时候崩溃，系统可能会处于不一致状态，需要在重启后恢复。 需要解决并发问题。同一时间可能有多个进程和文件系统进行交互，需要保证这些操作不破坏其中的不变性。 需要解决速度匹配问题。对磁盘的操作是很慢的，所以文件系统需要在内存中缓存磁盘块来提高效率。 文件系统分层结构 其中Disk层提供对磁盘块的读写服务，Buffer cache层缓存文件块，同时使用同步机制来限制同一时间只能有一个内核线程访问某个数据块。Logging层将进程对多个磁盘块的更新打包为事务，并将其设置为原子操作，以便在面对系统崩溃的时候进行恢复。Inode层提供了文件的概念，用一个带有唯一数字标号的inode以及多个磁盘块来代表一个文件。Directory层是特殊的inode，内部包含多个文件名和inode标号。Pathname层提供分层路径名，如/usr/rtm/xv6/fs.c，并通过递归查找进行解析。File descripter层使用文件系统接口抽象了许多Unix资源（例如，管道、设备、文件等），简化了应用程序程序员的生活。 这里需要区分两个概念。通常磁盘作为硬件，出厂设置的默认分块大小为512bytes，称为sector。而在操作系统通常会将多个sector合并成一个更大的操作单元，称为block。在xv6中，block的大小为2个sector，也就是1024bytes。xv6在用结构体buf来表示缓存在内存的磁盘块。 struct buf { int valid; // has data been read from disk? int disk; // does disk &quot;own&quot; buf? uint dev; uint blockno; struct sleeplock lock; uint refcnt; struct buf *prev; // LRU cache list struct buf *next; uchar data[BSIZE]; }; 文件系统通常吧磁盘划分为不同区域。其中block0通常是不使用的，该磁盘块用来存储操作系统的boot sector(引导程序)。block1被称为superblock，通常用来存储文件系统的元数据，包括文件系统的大小，block的块数等等。然后是日志块，inodes块和位图块，最后是数据块。 Buffer cache层 这一层主要提供两个服务，其一是限制对磁盘块的同步访问，以确保一个磁盘块在内存中的映射只有一个以及同一时间只有一个内核线程能够访问某个磁盘块映射。内存中的cache大小是有限的，因此只能缓存固定数量的磁盘块，当内核线程访问一个不在cache的磁盘块时，需要根据LRU策略来用新的磁盘块替换旧磁盘块。"},{"title":"环境配置","path":"/wiki/MIT-6.S081/index.html","content":"本地环境 设备：MacBook Air 2020 ( m1 芯片 ) 编译器：Apple clang version 14.0.0 (clang-1400.0.29.202) 问题清单 无穷递归 问题描述：error: infinite recursion detected [-Werror=infinite-recursion] 解决方法：在sh.c中runcmd函数签名上添加*_attribute_((noreturn))*"},{"title":"锁机制","path":"/wiki/MIT-6.S081/locks.html","content":"锁存在的目的是解决并发问题。操作系统之所以面对并发问题，是因为物理硬件的共享。现代的计算机一般是多核心，可以独立执行指令，他们共享着物理内存，因此存在着对同一块内存，一颗核心进行读，另外一颗核心进行写的情况。甚至多个核心同时写的情况。除此之外，即使只有一颗核心也需要应对多个线程切换，交错运行的场景。 并发是指由于多核并行、线程切换或中断导致的多指令流交替执行的情况 内核设计会允许大量的并发，以此来提高系统的性能。由此催生了以并发下正确性为目的的并发控制技术。 锁提供互斥，只有持有锁的CPU能够对该数据区进行操作，确保了对数据操作的正确性。但是它会限制系统性能，因为锁会序列化并发操作。 竞争条件 竞争条件就是同时对内存进行访问，并且其中至少有一个写操作。这样的情况通常会导致错误，并且难以调试。因为，添加一个打印语句从而增加的时间就可能消除了竞争条件。 解决竞争条件的方式一般就是加锁。 struct element *list = 0; struct lock listlock; void push(int data) { struct element *l; l = malloc(sizeof *l); l-&gt;data = data; acquire(&amp;listlock); l-&gt;next = list; list = l; release(&amp;listlock); } 这里acquire()和release()之间的区域也称为临界区。 通常所说的锁保护了数据，实际上是锁保护了对象的不变性质。比如在上述的push()中，list的性质是始终指向列表的表头，但是当执行完l-&gt;next = list后，这个不变性被暂时破坏了，如果有其他依赖于这个不变特性的指令在另外一个CPU并发执行，就会引起错误。所以锁实际上是保护了这样一种不变特性。 锁虽然能够保证代码的正确性，但是同时也会损失性能，从而失去多CPU运行的优势。同时，如果多个CPU同时请求锁会产生对锁的竞争，因此在真实的操作系统中设计了特殊的数据结构和算法来避免锁的竞争。 在xv6中存在两种锁，一种叫spinlock，另外一种叫sleep-lock。 spinlock是互斥锁，结构如下： // Mutual exclusion lock. struct spinlock { uint locked; // Is the lock held? // For debugging: char *name; // Name of lock. struct cpu *cpu; // The cpu holding the lock. }; 其中locked字段为0时表示该锁可获取，当该字段非零时，表示该锁已经被其他进程占有。 当进程想要申请锁的时候，我们一般会想到这样的函数： void acquire(struct spinlock* lk){ for(;;) { if(lk-&gt;locked == 0){ lk-&gt;locked = 1; break; } } } 但是这段代码在一些情况下会发生错误。比如当两个运行在不同CPU上的进程同时申请锁的时候，可能同时进行if检测。这样两个进程都申请到了锁，这就违背了互斥的原则。所以我们想通过某种方式让申请锁的过程保持原子性。通常在多核处理器上设计了内存和寄存器直接交换数据的汇编指令来实现原子性。在xv6中实现如下： acquire(struct spinlock *lk) { push_off(); // disable interrupts to avoid deadlock. if(holding(lk)) panic(&quot;acquire&quot;); // On RISC-V, sync_lock_test_and_set turns into an atomic swap: // a5 = 1 // s1 = &amp;lk-&gt;locked // amoswap.w.aq a5, a5, (s1) while(__sync_lock_test_and_set(&amp;lk-&gt;locked, 1) != 0) ; // Tell the C compiler and the processor to not move loads or stores // past this point, to ensure that the critical section&#39;s memory // references happen strictly after the lock is acquired. // On RISC-V, this emits a fence instruction. __sync_synchronize(); // Record info about lock acquisition for holding() and debugging. lk-&gt;cpu = mycpu(); } 我们不断通过原子操作去将lk-&gt;locked字段置 1 ，如果原来该字段的值为 1 那么我们置 1 并没有什么影响，但是如果原来为 0 ，我们就可以将该字段置为 1 并获得该锁。释放锁同样也是采用类似的方法实现的。 使用锁的难点在于，确定那些需要被保护的数据和不变性。这里有两个原则： 如果一个数据在被一个CPU写入的时候，同时能够被其他CPU读取或者写入，那么这个数据需要加锁。 如果一个不变性由多个地方的数据来构成，那么需要对构成该不变性的所有内存加锁。 除了需要知道何时加锁，避免使用多余的锁同样重要。因为过多的锁会减少系统的并发，从而降低性能。xv6中的kalloc()分配器就是典型的一个粗粒度锁，一个更好的做法是为每一个CPU维护一个空闲列表。xv6中的文件就是一个细粒度锁的方案，系统为每个文件都设置一个锁。如果想要实现多个进程对文件的不同位置进行读写，那么还可以设置粒度更为细致的锁。 死锁和锁排序 如果一个进程在内核中需要申请一系列锁，那么这需要其他所有进程都以相同的顺序获取这些锁。举个例子，进程A以lock_a，lock_b的顺序申请锁，那么其他进程想要同时申请这两个锁的时候就需要以相同的顺序申请。否则可能出现进程A已经成功申请lock_a，然而进程B成功申请了lock_b，两者相互等待的情况。这种情况被称为死锁。 为了解决这种情况，需要建立一个全局的锁申请顺序，所有函数只能按照这个顺序来申请锁。但是这个解决方案破坏了程序模块化设计的理念。 可重入锁 可重入锁，也叫递归锁。当一个进程已经占有了一个锁的时候，又在申请该锁，对于自旋锁来讲，这是典型的死锁。但是对于可重入锁来讲，这个操作是合法的，进程会继续运行。自旋锁更严格，有利于调试。但是如果合理设计，两种锁都是可以工作的。 锁与中断处理程序 中断处理程序和锁的并发会导致一些坏情况。比如在某个CPU上正在向控制台的缓冲区写入数据，但是此时控制台产生了中断，而且恰好被这个CPU响应。那么持有UART锁的进程被挂起，然后改CPU执行中断程序，此时中断程序就需要申请该锁。从而引发死锁问题。 在xv6中，采用了保守方案：一旦一个CPU持有锁，那么该CPU将不会响应任何中断。 这里需要注意的是，当进程申请锁的时候，首先禁止中断，接着才会自旋等待。如果先自旋，获得锁后再中断，仍然会存在一小段时间进程持有锁但是没有禁止中断，这会引发上述死锁问题。因此，在进程切换的时候，只能持有自己进程的锁，来避免死锁。 锁与程序执行顺序 现代的编译器一般会对代码指令进行优化，来提升程序的性能。但是对于并发程序而言，这种优化可能会破坏程序设计的初衷。比如将临界区内的指令调换到acquire()之前，或者将acquire()之前的指令调换到临界区内。这些都是我们不希望看到的，因此我们需要严格限制编译器的优化。 通过synchronizesynchronize()指令，能够限定编译器不会将这之前的指令调入到之后。 睡眠锁 自旋锁虽然能够有效将指令序列化来避免竞争条件，但是对于某些情况，自旋锁又很浪费CPU时间。比如文件的锁，因为文件操作通常消耗的时间较长，如果采用自旋锁，不仅其他申请该锁进程会自旋，而且该进程的CPU也不能被让出，十分浪费CPU资源。 持有自旋锁的进程不能够让出CPU，这是为了避免死锁。如果一个进程持有了锁，但是让出了CPU，新运行的进程也申请同样的锁，那么就会导致死锁。 因此我们需要一种进程即使持有它，但是也能允许中断和放弃CPU的锁，这就是睡眠锁。也正是由于这个特性，睡眠锁不能用在中断处理程序中，避免引发死锁。 总的来讲，睡眠锁适合用于临界区等待时间较长的场景。而自旋锁适合用于临界区等待时间较短的场景。"},{"title":"multithread","path":"/wiki/MIT-6.S081/multithread.html","content":"用户线程切换 背景：用户级线程相较于内核级线程更为轻量，因为不需要从用户态到内核态的切换。 任务 设计线程的创建和切换方案。完善user/uthread.c中的thread_create()和thread_schedule()，以及 user/uthread_switch.S中的thread_switch。 确保当thread_schedule()第一次运行给定线程时，该线程在其自己的堆栈上执行传递给thread_create()的函数。 另一个目标是确保thread_switch保存被切换的线程的寄存器，恢复被切换到的线程的寄存器，并返回到后一个线程指令中它最后停止的位置。修改struct thread以保存寄存器是不错的选择。 需要在thread_schedule中添加对thread_switch的调用；可以将任何需要的参数传递给thread_switch，但目的是从线程t切换到next_thread。 只需要保存callee-save registers。 user/uthread.asm中的汇编代码也许对调试有所帮助。 代码 uthread.c void thread_create(void (*func)()) { struct thread *t; for (t = all_thread; t &lt; all_thread + MAX_THREAD; t++) { if (t-&gt;state == FREE) break; } t-&gt;state = RUNNABLE; // YOUR CODE HERE t-&gt;context.ra = (uint64)func; t-&gt;context.sp = (uint64)t-&gt;stack + STACK_SIZE; } void thread_schedule(void) { struct thread *t, *next_thread; /* Find another runnable thread. */ next_thread = 0; t = current_thread + 1; for(int i = 0; i &lt; MAX_THREAD; i++){ if(t &gt;= all_thread + MAX_THREAD) t = all_thread; if(t-&gt;state == RUNNABLE) { next_thread = t; break; } t = t + 1; } if (next_thread == 0) { printf(&quot;thread_schedule: no runnable threads &quot;); exit(-1); } if (current_thread != next_thread) { /* switch threads? */ next_thread-&gt;state = RUNNING; t = current_thread; current_thread = next_thread; /* YOUR CODE HERE * Invoke thread_switch to switch from t to next_thread: * thread_switch(??, ??); */ thread_switch((uint64)&amp;t-&gt;context, (uint64)&amp;current_thread-&gt;context); } else next_thread = 0; } uthread_switch.S thread_switch: /* YOUR CODE HERE */ sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret /* return to ra */ 使用线程 代码 ph.c pthread_mutex_t lock; static void put(int key, int value) { int i = key % NBUCKET; // is the key already present? struct entry *e = 0; for (e = table[i]; e != 0; e = e-&gt;next) { if (e-&gt;key == key) break; } if(e){ // update the existing key. e-&gt;value = value; } else { // the new is new. pthread_mutex_lock(&amp;lock); insert(key, value, &amp;table[i], table[i]); pthread_mutex_unlock(&amp;lock); } } 围栏 代码 barrier static void barrier() { // YOUR CODE HERE // // Block until all threads have called barrier() and // then increment bstate.round. // pthread_mutex_lock(&amp;bstate.barrier_mutex); bstate.nthread++; if(bstate.nthread &lt; nthread) pthread_cond_wait(&amp;bstate.barrier_cond, &amp;bstate.barrier_mutex); if(bstate.nthread == nthread) { bstate.round++; bstate.nthread = 0; pthread_cond_broadcast(&amp;bstate.barrier_cond); } pthread_mutex_unlock(&amp;bstate.barrier_mutex); }"},{"title":"Network driver","path":"/wiki/MIT-6.S081/networking.html","content":"网络驱动 背景： 使用E1000网卡处理网络通信。事实上，qemu模拟了E1000和局域网。在这个模拟局域网上，xv6的IP地址为10.0.2.15，真实主机IP地址为10.0.2.2。当xv6使用E1000向10.0.2.2发送数据包时，会将数据包传递到真实主机上对应的应用程序。 packets.pcap文件中记录了传入和传出的数据包。通过一下命令查看： tcpdump -XXnr packets.pcap kernel/e1000.c包含e1000的初始化代码以及需要你完善的用于发送和接收数据包的函数。 kernel/e000_dev.h包含e1000定义的寄存器和标志位的定义，可以在英特尔E1000软件开发人员手册中进一步了解。 kernel/net.c和kernel/ne.h包含一个简单的网络协议栈，实现了IP、UDP和ARP协议。这些文件还包含用于保存数据包的数据结构，称为mbuf。 kernel/pci.c包含在xv6启动时在PCI总线上搜索E1000卡的代码。 任务 完善kernel/e1000.c用于发送和接收数据包的函数e1000_transmit()和e1000_recv() E1000的软件开发手册对你来说应该是有帮助的： Section 2对设备进行整体概述。 Section 3.2描述接收包的大致过程。 Section 3.3 和 Section 3.4描述发送包的大致过程。 Section 13介绍E1000的寄存器。 Section 14帮助你理解xv6中的初始化代码。 本手册涵盖了几个密切相关的以太网控制器。QEMU模拟82540EM。现在浏览第2章，感受一下设备。要写司机，您需要熟悉第3章和第14章以及4.1章（尽管不是4.1的小节）。您还需要使用第13章作为参考。其他章节主要涵盖了您的驱动程序不必与之交互的E1000组件。一开始不要担心细节；只要了解一下文档的结构，这样你以后就可以找到东西了。E1000有许多高级功能，其中大部分你可以忽略。完成这个实验室只需要一小套基本功能。 我们在e1000.c中为您提供的e1000_init()函数将E1000配置为读取要从RAM传输的数据包，并将接收的数据包写入RAM。这种技术被称为DMA，用于直接内存访问，指的是E1000硬件直接向/从RAM写入和读取数据包。 由于数据包的突发可能比驱动程序处理速度快，e1000_init()为E1000提供了多个缓冲区，E1000可以向其中写入数据包。E1000要求这些缓冲区由RAM中的“描述符”数组来描述；每个描述符都包含RAM中的地址，E1000可以写入接收的数据包。struct rx_desc描述了描述符格式。描述符数组称为接收环或接收队列。这是一个圆形环，当卡或驱动程序到达数组的末尾时，它会包装回开头。e1000_init()使用mbufalloc()将E1000的mbuf数据包缓冲区分配给DMA。还有一个传输环，驱动程序将它希望E1000发送的数据包放入其中。e1000_init()将两个环配置为具有RX_RING_SIZE和TX_RING_SIZE的大小。 当net.c中的网络堆栈需要发送数据包时，它会使用保存要发送的数据包的mbuf调用e1000_transmit()。您的传输代码必须在TX（传输）环的描述符中放置指向数据包数据的指针。struct tx_desc描述了描述符格式。您需要确保最终释放每个mbuf，但只有在E1000完成传输数据包后（E1000在描述符中设置E1000_TXD_STAT_DD位来指示这一点）。 当E1000从以太网接收每个数据包时，它首先将数据包发送到下一个RX（接收）环描述符指向的mbuf，然后生成中断。您的e1000_recv()代码必须扫描RX环，并通过调用net_rx()将每个新数据包的mbuf发送到网络堆栈（在net.c中）。然后，您需要分配一个新的mbuf并将其放入描述符中，这样当E1000再次到达RX环中的该点时，它会找到一个新的缓冲区，以便DMA一个新的数据包。 除了在RAM中读取和写入描述符环外，您的驱动程序还需要通过其内存映射的控制寄存器与E1000交互，以检测何时可用的数据包，并通知E1000驱动程序已用要发送的数据包填写了一些TX描述符。全局变量regs持有指向E1000第一个控制寄存器的指针；您的驱动程序可以通过将regs索引为数组来获取其他寄存器。您特别需要使用索引E1000_RDT和E1000_TDT。 要测试您的驱动程序，请在一个窗口中运行make服务器，在另一个窗口中运行make qemu，然后在xv6中运行nettests。nettests中的第一个测试试图将UDP数据包发送到主机操作系统，发送到使服务器运行的程序。如果您尚未完成实验室，E1000驱动程序实际上不会发送数据包，也不会发生任何事情。 完成实验室后，E1000驱动程序将发送数据包，qemu将将其发送到您的主机计算机，使服务器将看到它，它将发送响应数据包，然后E1000驱动程序和nettests将看到响应数据包。然而，在主机发送回复之前，它会向xv6发送一个“ARP”请求数据包，以查找其48位以太网地址，并希望xv6以ARP回复进行响应。一旦您完成E1000驱动程序的工作，kernel/net.c将处理此问题。如果一切顺利，nettests将打印测试ping：好的，并使服务器将打印来自xv6的消息！ 首先将打印语句添加到e1000_transmit()和e1000_recv()中，并运行make服务器和（在xv6中）nettests。您应该从打印语句中看到，nettests会生成对e1000_transmit的调用。 实现e1000_transmit的一些提示： 首先通过读取E1000_TDT控制寄存器，向E1000询问它期待下一个数据包的TX环形索引。 然后检查戒指是否溢出。如果E1000_TDT索引的描述符中没有设置E1000_TXD_STAT_DD，则E1000尚未完成相应的先前传输请求，因此返回错误。 否则，使用mbuffree（）释放从该描述符传输的最后一个mbuf（如果有的话）。 然后填写描述符。m-&gt;head指向内存中的数据包内容，m-&gt;len是数据包长度。设置必要的cmd标志（查看E1000手册中的第3.3节），并隐藏一个指向mbuf的指针，以便以后释放。 最后，通过在E1000_TDT modulo TX_RING_SIZE中添加一个来更新环形位置。 如果e1000_transmit()成功将mbuf添加到环中，则返回0。失败时（例如，没有可用的描述符来传输mbuf），返回-1，以便调用者知道释放mbuf。 实现e1000_recv的一些提示： 首先，通过获取E1000_RDT控制寄存器并添加一个模RX_RING_SIZE，向E1000询问下一个等待接收数据包（如果有的话）所在的环形索引。 然后通过检查描述符状态部分中的E1000_RXD_STAT_DD位来检查新数据包是否可用。如果没有，就停下来。 否则，将mbuf的m-&gt;len更新为描述符中报告的长度。使用net_rx()将mbuf传递到网络堆栈。 然后使用mbufalloc()分配一个新的mbuf来替换刚刚给net_rx()的mbuf。将其数据指针（m-&gt;head）编程到描述符中。将描述符的状态位清除为零。 最后，将E1000_RDT寄存器更新为处理的最后一个环描述符的索引。 e1000_init()用mbufs初始化RX环，你会想看看它是如何做到的，也许还可以借用代码。 在某个时候，曾经到达的数据包总数将超过环大小（16）；请确保您的代码可以处理。 您需要锁来应对xv6可能从多个进程使用E1000的可能性，或者在中断到达时可能在内核线程中使用E1000。"},{"title":"缺页异常","path":"/wiki/MIT-6.S081/page-faults.html","content":"一种辅助实现懒加载的机制 处理缺页异常 引发缺页异常的虚拟地址：存储在STVAL寄存器中 引发缺页异常的原因：存储在SCAUSE寄存器中 引发缺页异常的指令地址：存储在SEPC寄存器中 利用以上三个寄存器的信息，就能知道进入内核后如何处理缺页异常，并知道回到用户态时需要重新执行的指令的地址。 懒分配内存机制 在进程申请内存的时候，并不立即分配内存并映射到该进程的地址空间，而是仅对该进程的栈顶指针进行修改，等到进程真正使用申请的内存时，通过触发缺页错误进入内核从而真正分配物理内存。 未使用时0填充机制 地址空间：进程地址空间有三个区域，其中text区域存放指令，data区域存放初始化的全局变量，BSS区域存放未初始化或初始化为0的全局变量 原理：将BSS区域的所有页面全部映射到一个全为0的物理页面，从而节省程序启动时的物理内存分配。将BSS区域所有页面设置为只读，通过触发缺页异常进入内核真正分配一个全0的物理内存，并重新执行指令。 写时复制机制 fork系统调用创建子进程，子进程的页表和父进程页表共享物理内存，将子进程与父进程的PTES均设置为只读，只有当两者中任一个进程对内存有write时才会分配并复制内存，并将该页面映射到子进程。从而优化fork后立马调用exec的场景。 按需分配页面 在加载进程时，只加载部分指令到内存，其余PTES通过缺页异常来懒加载。涉及到页面置换问题。 内存映射文件 系统调用：mmap()从文件描述符对应的文件的偏移量的位置开始，映射长度为len的内容到虚拟内存地址VA，同时我们需要加上一些保护，比如只读或者读写。 原理：将完整或者部分文件加载到内存中，这样就可以通过内存地址相关的load或者store指令来操纵文件。"},{"title":"Page Tables","path":"/wiki/MIT-6.S081/page-tables.html","content":"检测被访问过的页面 背景：一些垃圾回收机制如果能够获取页面是否被访问的信息，将能够提高效率。 目的：实现检测页表访问位并将结果返回到用户态 预备知识：RISC-V硬件处理TLB缺失时，将新的虚拟地址载入时，会将相应的页面访问位置位 任务 代码实现在kernel/sysproc.c中的sys_pgaccess()，参数如下 第一个要检查的用户页面的虚拟地址 将要检查页面的数量 用于返回掩码结果的用户空间地址 使用argaddr()和argint()解析参数 最好在内核使用一个临时的缓冲区保存要输出的位掩码，利用copyout()输出 可以设置扫描页面数量的上限 使用walk()来找到正确的PTE 需要在kernel/riscv.h中定义PTE_A 确保检查PTE_A后，将其清零。否则无法判断在上次检查之后该页面有没有再次被访问 使用vmprint()来帮助debug 代码"},{"title":"调度","path":"/wiki/MIT-6.S081/scheduling.html","content":"操作系统运行中同时运行的进程通常比核心的数量多，那么这些进程是怎样“同时”运行的呢？操作系统给这些进程提供了怎样的抽象呢？操作系统如何实现这个抽象的呢？ 复用 xv6在两种情况下会发生进程切换，第一种是当IO操作完成时，存在等待它的进程，sleep-wakeup机制会进行进程切换；第二种是一个进程的时间片到时。 这样就给每一个进线提供了CPU的抽象。宏观上来看，似乎每个线程都有自己独占的CPU，就类似于页表使每个进程仿佛有自己的独有内存一样。 在设计这样的一个抽象的时候。我们需要考虑一些问题： 如何实现一个进程切换到另外一个进程？虽然其上下文切换的思想很简单，但是代码写起来却相当麻烦。 如何实现切换进程的同时用户无法感知？在xv6中使用定时器来实现的。 如何避免就绪进程队列的竞争条件问题？多个CPU会竞争就绪队列的进程，需要用lock来解决。 如何对已结束进程的所有资源进行回收？虽然进程本身可以释放部分资源，但是它无法释放一些自己的核心资源，比如内核堆栈。 在Linux中，一个进程可能拥有多个线程，这些线程共享内存。在xv6中有内核线程的概念，因此在xv6内核中，线程是共享内存的。但在用户空间中一般是一个进程中只有一个线程，因此用户空间中的线程可以视为相互隔离的。 上下文切换 线程切换的大致流程是用户程序因为中断或者系统调用进入内核，然后该进程的内核线程切换到scheduler线程，再由scheduler线程从就绪列表选择合适的新内核线程进行切换。其中scheduler线程是依赖于CPU的，也就是说每个CPU都维护了一个自己的scheduler。 线程的切换主要包括寄存器的保存和恢复，包括PC和堆栈指针的保存和恢复。在swtch中我们保存了当前线程的寄存器，并载入新线程的寄存器。并没有保存PC而是保存RA，这是调用swtch的地址。 scheduler线程是依赖于CPU的并且一直运行scheduler()函数的专用线程。 需要注意的是，并非所有的线程切换都是时间片用尽导致的，线程结束调用exit()也能导致线程切换。 代码流程 struct proc { struct spinlock lock; // p-&gt;lock must be held when using these: enum procstate state; // Process state ... // these are private to the process, so p-&gt;lock need not be held. uint64 kstack; // Virtual address of kernel stack ... struct trapframe *trapframe; // data page for trampoline.S struct context context; // swtch() here to run process ... }; 上面是线程切换需要用到的一些字段。其中state保存了进程的状态；kstack保存了进程的内核堆栈指针；trapframe保存了用户线程的寄存器；lock保护了很多地方线程的一致性；context保存了内核线程的寄存器状态。 想要区分不同进程的内核线程可以通过一些方式：第一，利用内核堆栈的不同来判断，因为每个用户进程都有自己的内核堆栈；第二，则是通过myproc()函数来判断，该函数通过读取tp寄存器的值来确定当前的CPU编号，同时利用一个记录所有CPU上运行的进程的数组来判断。 // Give up the CPU for one scheduling round. void yield(void) { struct proc *p = myproc(); acquire(&amp;p-&gt;lock); p-&gt;state = RUNNABLE; sched(); release(&amp;p-&gt;lock); } yield()之所以要获取进程锁是为了避免不一致状态。如果没有申请锁，那么当p-&gt;state修改为RUNABLE后，此时进程的状态表示其不在运行，但是实际上其仍然在接着运行sched()函数，若此时另外一个CPU选择运行该线程，那么此时就有两个CPU在同一个个堆栈上运行了。 .globl swtch swtch: sd ra, 0(a0) sd sp, 8(a0) sd s0, 16(a0) sd s1, 24(a0) sd s2, 32(a0) sd s3, 40(a0) sd s4, 48(a0) sd s5, 56(a0) sd s6, 64(a0) sd s7, 72(a0) sd s8, 80(a0) sd s9, 88(a0) sd s10, 96(a0) sd s11, 104(a0) ld ra, 0(a1) ld sp, 8(a1) ld s0, 16(a1) ld s1, 24(a1) ld s2, 32(a1) ld s3, 40(a1) ld s4, 48(a1) ld s5, 56(a1) ld s6, 64(a1) ld s7, 72(a1) ld s8, 80(a1) ld s9, 88(a1) ld s10, 96(a1) ld s11, 104(a1) ret 这里需要注意的是，xv6中明明有32个寄存器，而这里只保存了14个。这是因为当线程调用sched()函数的时候，是以函数调用的方式进行的，因此部分寄存器已经在内核堆栈中保存，并且在函数返回的时候会自动恢复，所以不用专门去做保存。 void scheduler(void) { struct proc *p; struct cpu *c = mycpu(); c-&gt;proc = 0; for(;;){ // Avoid deadlock by ensuring that devices can interrupt. intr_on(); for(p = proc; p &lt; &amp;proc[NPROC]; p++) { acquire(&amp;p-&gt;lock); if(p-&gt;state == RUNNABLE) { // Switch to chosen process. It is the process&#39;s job // to release its lock and then reacquire it // before jumping back to us. p-&gt;state = RUNNING; c-&gt;proc = p; swtch(&amp;c-&gt;context, &amp;p-&gt;context); // Process is done running for now. // It should have changed its p-&gt;state before coming back. c-&gt;proc = 0; } release(&amp;p-&gt;lock); } } }"},{"title":"睡眠唤醒机制","path":"/wiki/MIT-6.S081/sleep&wakeup.html","content":"通过调度，实现了进程间的隔离。但是真实的操作系统中，往往进程之间存在通信，比如一个进程等待硬盘读写，如何解决这个问题呢？ 睡眠唤醒机制 xv6中的睡眠唤醒机制是一个相对底层的接口，通过这个机制可以实现一个更高级的接口，通常被称为信号量。信号量的典型方法被称为PV操作，通常是给信号量做加减。 struct semaphore { spinlock lock; int count; } void P(struct semaphore* s) { acquire(s-&gt;lock); while(s-&gt;count == 0) sleep(s, s-&gt;lock); s-&gt;count -= 1; release(s-&gt;lock); } void V(struct semaphore* s) { acquire(s-&gt;lock); s-&gt;count++; weakup(s); release(s-&gt;lock); } 通过睡眠唤醒机制避免忙等待，同时为了避免唤醒丢失和死锁，所以在sleep中传入锁。 void P(struct semaphore* s) { while(s-&gt;count == 0) sleep(s); acquire(s-&gt;lock); s-&gt;count -= 1; release(s-&gt;lock); } void V(struct semaphore* s) { acquire(s-&gt;lock); s-&gt;count++; weakup(s); release(s-&gt;lock); } 上述代码就可能出现唤醒丢失的情况。因为sleep(s)和判断条件之间存在小段时间，可能s-&gt;count不为0，但是进程进入睡眠了，破坏了进程仅在计数为0时睡眠的不变性，从而错过唤醒，进程睡死。 接下来是xv6中实现睡眠唤醒机制的真实代码： // Atomically release lock and sleep on chan. // Reacquires lock when awakened. void sleep(void *chan, struct spinlock *lk) { struct proc *p = myproc(); // Must acquire p-&gt;lock in order to // change p-&gt;state and then call sched. // Once we hold p-&gt;lock, we can be // guaranteed that we won&#39;t miss any wakeup // (wakeup locks p-&gt;lock), // so it&#39;s okay to release lk. acquire(&amp;p-&gt;lock); //DOC: sleeplock1 release(lk); // Go to sleep. p-&gt;chan = chan; p-&gt;state = SLEEPING; sched(); // Tidy up. p-&gt;chan = 0; // Reacquire original lock. release(&amp;p-&gt;lock); acquire(lk); } // Wake up all processes sleeping on chan. // Must be called without any p-&gt;lock. void wakeup(void *chan) { struct proc *p; for(p = proc; p &lt; &amp;proc[NPROC]; p++) { if(p != myproc()){ acquire(&amp;p-&gt;lock); if(p-&gt;state == SLEEPING &amp;&amp; p-&gt;chan == chan) { p-&gt;state = RUNNABLE; } release(&amp;p-&gt;lock); } } }"},{"title":"陷阱和系统调用","path":"/wiki/MIT-6.S081/traps-syscall.html","content":"陷阱机制 内核通过对特定控制寄存器进行写操作，CPU利用这些寄存器的信息处理陷阱 特殊控制寄存器 STVEC：保存陷阱处理代码的地址 SEPC：保存进入陷阱前的PC SCAUSE：保存陷阱的类型 SSCRATCH： SSTATUS：分为SIE位、SPP位，前者控制中断使能，后者表示陷阱来自内核态还是用户态 以上这些特殊控制寄存器只能在特权级进行修改 大致流程 禁用中断(SIE位清零) 保存PC至SEPC 保存发生陷阱时的特权级别(SPP位) 设置SCAUSE(反应陷阱的原因) 设置CPU到内核态 将STVEC复制到PC 执行新PC 注意事项：目前仅仅在用户态做了很少的工作，即没有切换页表，也没有切换内核堆栈，更没有保存任何寄存器。 来自用户态的陷阱 用户态陷阱的执行过程 uservecusertrapusertrapsetuserret 蹦床页面：由于最初并未对页表进行切换，因此STEVC必须同时在内核页表和用户进程页表中进行有效映射 该页面被映射到每个进程的地址空间的最高地址处 保存现场：保存进入陷阱前的32个寄存器状态，此时需要SSCRATCH辅助保存，因为此时没有空闲通用寄存器 将与SSCRATCH交换数据，在交换之后内部存储的是Trampframe的基址 TRAMPFRAME 映射到每个进程地址空间蹦床页面下方，并设置为特权级可访问 用于存储进入陷阱前状态以及返回值，此页面由内核维护，用户进程不能访问 存放着当前进程的内核堆栈地址 存放着内核页表的地址 CPU标示号 陷阱处理C函数地址 USERTRAP 确定造成陷阱的原因，对陷阱处理，并返回 首先将STVEC更改为kernelvec，这样在内核中发生的TRAP就是被kernelvec处理 然后保存SEPC，因为TRAP过程中可能会调用yield（时钟中断）函数切换到另外一个进程的内核线程，该线程可能会返回用户空间，这个过程将会改变SEPC的值。 根据TRAP的不同类型分别处理 将程序计数器加4：当前的程序计数器指向ecall，我们希望TRAP执行完后执行ecall的下一条指令 最后检查该设备中断是否是时钟中断，若是则执行yield函数放弃CPU 返回用户空间 usertrapret 配置TRAPFRAME以处理下一次来自用户空间的TRAP。包括配置STVEC为uservec，配置SEPC为之前的程序计数器，配置uservec依赖的各种参数(kernel_pgtbl...)，最后调用userret userret 接收TRAPFRAME和PGTBL参数。首先将TRAPFRAME中保存的与SSCRATCH交换，交换后存储的是TRAPFRAME的地址，以其为基址将TRAPFRAME中保存的状态恢复到CPU中的寄存器中。最后与SSCRATCH交换，以便下一次TRAP发生时，SSCRATCH保存着该进程的TRAPFRAME的地址 来自内核态的陷阱 保存现场：kernelvec首先将寄存器状态压入该线程的内核堆栈，以便当TRAP返回的时候从堆栈恢复现场，接着调用kerneltrap 陷阱类型：来自内核态的陷阱的类型分为设备中断和异常。若是设备中断，则会检查并执行相应的例程。若是异常，操作系统则会崩溃 定时器中断是设备中断中比较特殊的存在。当前线程会放弃CPU，在将来某个时间点通过堆栈恢复状态继续执行。 返回：复制SEPC到PC，并恢复现场。"},{"title":"Traps","path":"/wiki/MIT-6.S081/traps.html","content":"帧指针、栈指针是函数调用的灵魂，栈指针负责为局部变量和参数分配空间，帧指针扮演寻找变量和参数的基石 内核堆栈和进程堆栈没有联系，只是他们都和进程一一对应 RISC-V汇编初识 目的：了解RISC-V中的汇编指令 预备知识：汇编语言 任务 编译fs.img，阅读call.asm中的g、f、main函数。回答以下问题并将答案编辑在answers-traps.txt文件之中 哪些寄存器保存传递给函数的参数，例如：当main函数调用printf函数时，哪个寄存器保存了13？ ，其中调用printf时，寄存器保存了13 在main函数的汇编码中，哪里调用了f，g这两个函数 函数 printf 位于什么地址？ 0x616，在RISCV指令中，auipc指令一般结合其他跳转指令来执行，因为在RISCV指令中无法表示32位的立即数，因此需要用auipc指令将一个20位立即数左移12位加上PC，存储在目的寄存器中。然后再由接下来的跳转指令用12位立即数填充低12位，最后实现跳转到PC附近的32位地址。这里的计算就是： 在 jalr 到 main 中的 printf 之后，寄存器 ra 中的值是什么？ 38，即当前地址+4 运行以下代码 unsigned int i = 0x00646c72; printf(&quot;H%x Wo%s&quot;, 57616, &amp;i); 请问输出是什么？(这段代码的输出依赖于RISC-V的小端模式)。若这段代码运行在大端模式的机器中，要使输出相同，应该给赋什么值？需要将57616改为其他值么？ 输出是Hell0 World，不用更改57616，只需要将0x00646c72改为0x726c6400 在这行代码中 printf(&quot;x=%d y=%d&quot;, 3); 后面会出现什么数字？(提示：这个数据不是某个特定的数字) 为什么会出现这种情况？ y后面的数字是随机的数字，取决于从栈帧中取到a2的垃圾数据 堆栈回溯 背景：在调试过程中，如果知道在出错点处的堆栈中存在哪些没有返回的函数调用是非常有帮助的 任务 在kernel/printf.c中实现backtrace()函数，并在sys_sleep中调用 在panic函数中调用backtrace，以便在系统崩溃时了解相关信息 代码 修改riscv.h // read the s0 register static inline uint64 r_fp() { uint64 x; asm volatile(&quot;mv %0, s0&quot; : &quot;=r&quot; (x) ); return x; } backtrace() void backtrace(void) { printf(&quot;backtrace: &quot;); uint64 fp = r_fp(); uint64 head = PGROUNDDOWN(fp); uint64 tail = PGROUNDUP(fp); uint64 ra; while((fp &gt;= head) &amp;&amp; fp &lt;= tail){ ra = *(uint64*)(fp - 8); fp = *(uint64*)(fp - 16); printf(&quot;%p &quot;, ra); } } panic(char* s) void panic(char *s) { pr.locking = 0; printf(&quot;panic: &quot;); printf(s); printf(&quot; &quot;); backtrace(); panicked = 1; // freeze uart output from other CPUs for(;;) ; } sys_sleep uint64 sys_sleep(void) { int n; uint ticks0; if(argint(0, &amp;n) &lt; 0) return -1; acquire(&amp;tickslock); ticks0 = ticks; while(ticks - ticks0 &lt; n){ if(myproc()-&gt;killed){ release(&amp;tickslock); return -1; } sleep(&amp;ticks, &amp;tickslock); } release(&amp;tickslock); backtrace(); return 0; } 闹钟 背景：计算密集型进程往往想知道自己消耗了多少时间，同时一些进程希望定期做某件任务 任务 实现一个用户级中断处理程序，sigalarm(interval, handler) 调用sigalarm(n, fn)的函数每经过n个CPU时钟，kernel就会调用fn，当fn返回后，进程恢复继续执行。(本质就是TRAP) 当应用调用sigalarm(0,0)时，kernel应该停止周期闹铃 在Makefile中添加alarmtest.c，同时在kernel添加sigalarm和sigturn user/alarmtest.asm或许对调试有所帮助 代码 修改Makefile ifeq ($(LAB),traps) UPROGS += \\ $U/_call\\ $U/_bttest\\ $U/_alarmtest endif 修改usys.pl entry(&quot;sigalarm&quot;); entry(&quot;sigreturn&quot;); 修改syscall.h #define SYS_sigalarm 22 #define SYS_sigreturn 23 修改syscall.c ... extern uint64 sys_sigalarm(void); extern uint64 sys_sigturn(void); static uint64 (*syscalls[])(void) = { ... [SYS_sigalarm] sys_sigalarm, [SYS_sigreturn] sys_sigreturn, } 修改proc.h struct proc { ... // these are private to the process, so p-&gt;lock need not be held. ... uint64 interval; // call handler for every interval ticks uint64 handler; // run every interval ticks uint64 count; // time left to call handler ... } 修改proc.c static struct proc* allocproc(void) { ... p-&gt;count = 0; ... } int sigalarm(uint64 interval, uint64 handler) { struct proc *p = myproc(); p-&gt;interval = interval; p-&gt;handler = handler; return 0; } 修改trap.c if(which_dev == 2){ if(++p-&gt;count &gt;= p-&gt;interval) { p-&gt;trapframe-&gt;epc = p-&gt;handler; p-&gt;count = 0; } yield(); } 修改sysproc.c uint64 sys_sigalarm(void) { uint64 interval; uint64 handler; if(argaddr(0, &amp;interval) &lt; 0) return -1; if(argaddr(1, &amp;handler) &lt; 0) return -1; return sigalarm(interval, handler); }"}]